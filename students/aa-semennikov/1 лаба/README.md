# Лабораторная работа №1

## Датасет

Для решения задачи был выбран датасет для предсказания цены авиабилетов ([ссылка](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction)).

## Реализация бэггинга
При инициализации алгоритма задается количество деревьев, а также границы метрик для обучающей и тестовой выборок. Затем, пока не наберется достаточное количество деревьев, на каждой итерации формируется подвыборка обучающего набора данных размером 2/3, на которой обучается соответствующее дерево. Вычисляются значения `R^2` на обучающей выборке и на тесте и в случае, если они выше заданных пороговых значений, дерево добавляется в ансамбль. 

При предсказании итоговый прогноз получается в результате усреднения прогнозов всех деревьев ансамбля.

## Сравнение с библиотечной реализацией 
`R^2`: 0.9839 у кастомного алгоритма vs 0.9944 у библиотечной реализации.

Для кросс-валидации использовалась функция ниже:
```python
def cross_validate(model, X, y, n_folds=5):
    scores = []
    for n in range(n_folds):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
        model.fit(X_train, y_train)
        scores += [r2_score(model.predict(X_test), y_test)]
    return scores
```
На 10 фолдах средний R2 кастомного алгоритма составил 0.995, реализации sklearn - 0.985.

## Время обучения
Кастомный алгоритм обучался чуть дольше: 46.91 с. vs 37.40 с у библиотечного алгоритма.
