# Лабораторная работа №3

## Датасет

Для решения задачи был выбран датасет для классификации цветков ириса ([ссылка](https://www.kaggle.com/datasets/himanshunakrani/iris-dataset)).

## Реализация
При обучении считается априорная вероятность для каждого класса, а также среднее и ст. отклонение по всем признакам для каждого класса. При предсказании априорные вероятности логарифмируются, а для каждого примера вычисляется логарифм правдоподобия принадлежности к каждому из классов. Затем упомянутые логарифмы складываются, а `argmax` полученных вероятностей становится итоговым предсказанием.

## Сравнение с библиотечной реализацией 
### Метрики 
Кастомный алгоритм
```
             precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00         9
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30
```
Библиотечная реализация
```
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00         9
           2       1.00      1.00      1.00        11

    accuracy                           1.00        30
   macro avg       1.00      1.00      1.00        30
weighted avg       1.00      1.00      1.00        30
```
### Время обучения 
Время обучения кастомного алгоритма: 0.01 с
Время обучения библиотечной реализации: < 0.01 с

Для кросс-валидации использовалась функция ниже: 
```python
def cross_validate(model, X, y, n_folds=5):
    scores = []
    for n in range(n_folds):
        model_to_fit = copy.deepcopy(model)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
        model_to_fit.fit(X_train, y_train)
        scores += [accuracy_score(y_test, model_to_fit.predict(X_test.to_numpy()))]
    return scores
```
На 20 выборках средняя accuracy кастомного алгоритма оказалась чуть выше (0.966 vs 0.942)