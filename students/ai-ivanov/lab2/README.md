# Gradient boosting

## Набор данных

https://www.kaggle.com/datasets/uciml/autompg-dataset?resource=download

> The data concerns city-cycle fuel consumption in miles per gallon,
to be predicted in terms of 3 multivalued discrete and 5 continuous
attributes." (Quinlan, 1993)

## Теоретические основы

**Градиентный бустинг** - это мощный алгоритм машинного обучения, который построен на принципе последовательного обучения слабых моделей (чаще всего решающих деревьев), где каждая следующая модель пытается исправить ошибки предыдущих.

### Основные принципы

1. **Последовательное обучение**: Модели обучаются одна за другой, каждая последующая фокусируется на ошибках предыдущих.

2. **Минимизация функции потерь**: Алгоритм стремится минимизировать функцию потерь $L(y, F(x))$, где $y$ - истинное значение, а $F(x)$ - предсказание модели.

3. **Аддитивность**: Итоговая модель представляет собой сумму всех слабых моделей:

$$F_M(x) = \sum_{m=1}^M h_m(x)$$

где $M$ - количество итераций, $h_m(x)$ - слабая модель на m-й итерации.

### Математическое описание алгоритма

1. **Инициализация модели**:
   $$F_0(x) = \arg\min_{\gamma} \sum_{i=1}^n L(y_i, \gamma)$$
   
   **Пояснение**: 
   - $F_0(x)$ - начальная модель (константа)
   - $\gamma$ - константное значение, которое минимизирует функцию потерь для всех наблюдений
   - $L(y_i, \gamma)$ - значение функции потерь при предсказании $\gamma$ и истинном значении $y_i$
   - Для MSE эта начальная константа равна среднему всех $y_i$
   - Для логистической функции потерь это log odds положительного класса

2. **Для каждой итерации m = 1, ..., M**:
   
   a. Вычисление псевдоостатков:
   $$r_{im} = -\left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)}$$
   
   **Пояснение**:
   - $r_{im}$ - псевдоостаток для i-го наблюдения на m-й итерации
   - $\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}$ - градиент функции потерь по предсказанному значению
   - Знак минус превращает градиент в антиградиент (направление уменьшения ошибки)
   - $F_{m-1}(x)$ - текущая модель, относительно которой вычисляется градиент
   - Для MSE псевдоостаток равен $(y_i - F_{m-1}(x_i))$ - разнице между истинным и предсказанным значением
   
   b. Обучение слабой модели $h_m(x)$ на псевдоостатках
   
   **Пояснение**:
   - $h_m(x)$ - слабая модель (обычно решающее дерево), обучаемая на m-й итерации
   - Эта модель пытается предсказать псевдоостатки $r_{im}$ по признакам $x_i$
   - Решающее дерево разбивает пространство признаков на регионы и в каждом регионе делает константное предсказание
   - Глубина дерева определяет сложность модели (обычно используются неглубокие деревья)

   c. Поиск оптимального шага:
   $$\gamma_m = \arg\min_{\gamma} \sum_{i=1}^n L(y_i, F_{m-1}(x_i) + \gamma h_m(x_i))$$
   
   **Пояснение**:
   - $\gamma_m$ - оптимальный коэффициент (вес) для текущей слабой модели
   - Задача этого шага - определить, с каким весом включить текущую модель $h_m(x)$ в ансамбль
   - Для деревьев обычно определяется отдельный $\gamma$ для каждого листа дерева
   - Для MSE $\gamma$ в каждом листе равен среднему значению псевдоостатков в этом листе
   - Можно представить как "калибровку" значений, предсказанных деревом
   
   d. Обновление модели:
   $$F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)$$
   
   **Пояснение**:
   - $F_m(x)$ - обновленная модель после m-й итерации
   - $F_{m-1}(x)$ - предыдущая модель
   - $\gamma_m h_m(x)$ - вклад новой слабой модели, скорректированный оптимальным коэффициентом
   - Модель строится аддитивно, каждая новая слабая модель добавляется к сумме предыдущих

### Особенности алгоритма

1. **Регуляризация**:
   - Скорость обучения (learning rate) $\eta$:
     $$F_m(x) = F_{m-1}(x) + \eta \gamma_m h_m(x)$$
     
     **Пояснение**:
     - $\eta$ - гиперпараметр, контролирующий скорость обучения (обычно 0.01-0.3)
     - Уменьшает вклад каждой новой модели в ансамбль
     - Меньшие значения $\eta$ требуют больше итераций, но часто дают лучшие результаты
     - Это форма "сжатия" (shrinkage), которая помогает предотвратить переобучение
     
   - Случайное подвыборка данных (subsampling)
     
     **Пояснение**:
     - На каждой итерации используется только часть обучающих данных (например, 50%)
     - Это вносит стохастичность в процесс обучения
     - Помогает предотвратить переобучение и ускоряет обучение
     - Формально это баггинг, интегрированный в процесс бустинга
     
   - Ограничение глубины деревьев
     
     **Пояснение**:
     - Ограничение максимального количества узлов или глубины деревьев
     - Неглубокие деревья (3-8 уровней) обычно достаточны и предотвращают переобучение
     - Каждый узел дерева соответствует разбиению пространства признаков по одному из признаков

2. **Функции потерь**:
   - Для регрессии: MSE $L(y, F) = \frac{1}{2}(y - F)^2$
     
     **Пояснение**:
     - $y$ - истинное значение
     - $F$ - предсказанное значение
     - Штрафует квадрат ошибки, большие ошибки штрафуются непропорционально сильнее
     - Множитель $\frac{1}{2}$ упрощает вычисление градиента
     
   - Для классификации: Log loss $L(y, F) = \log(1 + e^{-yF})$
     
     **Пояснение**:
     - $y \in \{-1, 1\}$ - метка класса
     - $F$ - предсказанное значение (log odds)
     - Превращается в вероятность через сигмоиду: $p = \frac{1}{1 + e^{-F}}$
     - Штрафует уверенные неправильные предсказания очень сильно

## Градиентный бустинг: глубокое понимание

### Какую задачу решает градиентный бустинг?

Градиентный бустинг решает фундаментальную задачу машинного обучения: нахождение функции $F(x)$, которая минимизирует ожидаемую функцию потерь $L(y, F(x))$ на всех возможных входных данных. Другими словами, мы ищем:

$$F^* = \arg\min_F \mathbb{E}_{x,y}[L(y, F(x))]$$

Эта функция $F(x)$ может решать различные задачи:
- **Регрессия**: предсказание числового значения
- **Бинарная классификация**: определение класса (0 или 1)
- **Многоклассовая классификация**: определение одного из нескольких классов
- **Ранжирование**: сортировка элементов по релевантности

### Почему градиентный бустинг так устроен?

#### Градиентный спуск для функций

Традиционный градиентный спуск минимизирует функцию $f(w)$ путем итеративного обновления параметров $w$:

$$w_{t+1} = w_t - \eta \nabla f(w_t)$$

где $\nabla f(w_t)$ - градиент функции, а $\eta$ - скорость обучения.

#### Градиентный спуск для функционалов

В градиентном бустинге мы минимизируем не функцию, а функционал - "функцию от функций":

$$\mathcal{L}(F) = \mathbb{E}_{x,y}[L(y, F(x))]$$

Вместо обновления параметров $w$, мы обновляем всю функцию $F$:

$$F_{m}(x) = F_{m-1}(x) - \eta \nabla \mathcal{L}(F_{m-1})$$

Здесь $\nabla \mathcal{L}(F_{m-1})$ представляет собой функциональный градиент, который для каждого $x_i$ равен:

$$\nabla \mathcal{L}(F_{m-1})(x_i) = \frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\bigg|_{F=F_{m-1}}$$

#### Аппроксимация функционального градиента

Градиентный бустинг не может напрямую вычислить функциональный градиент для всех возможных $x$. Вместо этого:

1. Вычисляются отрицательные градиенты функции потерь (псевдоостатки) для каждого обучающего примера:
   $$r_{im} = -\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\bigg|_{F=F_{m-1}}$$

2. Обучается слабая модель $h_m(x)$ (обычно решающее дерево), которая аппроксимирует эти псевдоостатки

3. Модель обновляется: $F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x)$

### Регуляризация и предотвращение переобучения

Градиентный бустинг склонен к переобучению из-за своей мощности. Для контроля этого применяются следующие техники:

1. **Скорость обучения (learning rate) $\eta$**: 
   - Маленькие значения (0.01-0.1) замедляют обучение, но повышают обобщающую способность
   - Формула обновления: $F_m(x) = F_{m-1}(x) + \eta \cdot \gamma_m h_m(x)$

2. **Подвыборка данных (stochastic gradient boosting)**:
   - На каждой итерации используется только случайная подвыборка обучающих данных (например, 50%)
   - Добавляет случайность и предотвращает переобучение

3. **Ограничение сложности базовых моделей**:
   - Максимальная глубина деревьев (обычно 3-8)
   - Минимальное количество наблюдений в листьях
   - Максимальное количество листьев

4. **Регуляризация функции потерь**:
   - L1-регуляризация (LASSO): штраф за абсолютные значения предсказаний
   - L2-регуляризация (Ridge): штраф за квадраты предсказаний

### Преимущества градиентного бустинга

1. **Высокая точность**: Один из самых точных алгоритмов машинного обучения
2. **Работа с разнородными данными**: Нет необходимости в предварительной обработке
3. **Встроенный отбор признаков**: Важность признаков определяется автоматически
4. **Устойчивость к выбросам**: Благодаря возможности использования различных функций потерь
5. **Интерпретируемость**: Можно анализировать отдельные деревья и важность признаков

## Реализация на python

```python
class GradientBoostingRegressor(BaseEstimator, RegressorMixin):
    def __init__(
        self,
        n_estimators: int = 100,
        learning_rate: float = 0.1,
        max_depth: int = 3,
        subsample: float = 1.0,
        random_state: int | None = None,
    ):
        """
        Инициализация градиентного бустинга для задачи регрессии

        Args:
            n_estimators: количество базовых моделей (деревьев)
            learning_rate: скорость обучения (темп)
            max_depth: максимальная глубина деревьев
            subsample: доля выборки для каждого дерева (случайная подвыборка)
            random_state: фиксация генератора случайных чисел
        """
        self.n_estimators = n_estimators
        self.learning_rate = learning_rate
        self.max_depth = max_depth
        self.subsample = subsample
        self.random_state = random_state

        # Список для хранения базовых моделей
        self.trees: list[DecisionTreeRegressor] = []
        # Начальное значение предсказания (среднее по выборке)
        self.initial_prediction: float | None = None

    def fit(self, X: np.ndarray, y: np.ndarray) -> "GradientBoostingRegressor":
        """
        Обучение модели градиентного бустинга

        Args:
            X: матрица признаков
            y: целевая переменная

        Returns:
            self: обученная модель
        """
        # Инициализация генератора случайных чисел
        rng = np.random.RandomState(self.random_state)

        # Инициализация начального предсказания как среднего значения
        self.initial_prediction = np.mean(y)
        F = np.full_like(y, self.initial_prediction, dtype=np.float64)

        # Последовательное обучение деревьев
        for _ in range(self.n_estimators):
            # Вычисление псевдоостатков (градиентов)
            residuals = y - F

            # Создание подвыборки, если subsample < 1
            if self.subsample < 1.0:
                sample_mask = rng.rand(len(y)) < self.subsample
                subsample_X = X[sample_mask]
                subsample_residuals = residuals[sample_mask]
            else:
                subsample_X = X
                subsample_residuals = residuals

            # Создание и обучение нового дерева на псевдоостатках
            tree = DecisionTreeRegressor(
                max_depth=self.max_depth, random_state=self.random_state
            )
            tree.fit(subsample_X, subsample_residuals)

            # Добавление дерева в список
            self.trees.append(tree)

            # Обновление текущих предсказаний
            F += self.learning_rate * tree.predict(X)

        return self

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Получение предсказаний модели

        Args:
            X: матрица признаков

        Returns:
            predictions: массив предсказаний
        """
        # Проверка, что модель обучена
        if not self.trees or self.initial_prediction is None:
            raise ValueError("Model must be fitted before making predictions")

        # Начальное предсказание
        predictions = np.full(X.shape[0], self.initial_prediction, dtype=np.float64)

        # Добавление вклада каждого дерева
        for tree in self.trees:
            predictions += self.learning_rate * tree.predict(X)

        return predictions
```

## Результаты экспериментов

### Сравнение с реализацией sklearn

#### Кросс-валидация (5 фолдов)

**Custom реализация:**
- MSE: 0.1578 (+/- 0.2406)
- R2: 0.7434 (+/- 0.4057)

**Sklearn реализация:**
- MSE: 0.1595 (+/- 0.2480)
- R2: 0.7407 (+/- 0.4183)

**Разница в процентах:**
- MSE: 1.05%
- R2: 0.37%

**Разница во времени**

Custom реализация медленнее в 1.4 раза.

### Подбор гиперпараметров

**Лучшие параметры:**
- learning_rate: 0.1
- max_depth: 2
- n_estimators: 100
- subsample: 0.7

**Результаты лучшей модели на кросс-валидации:**
- MSE: 0.1370 (+/- 0.1659)
- R2: 0.7806 (+/- 0.2701)

## Выводы

В ходе выполнения лабораторной работы была реализована собственная версия алгоритма градиентного бустинга для задач регрессии. Сравнительный анализ с реализацией из библиотеки sklearn показал, что разработанная модель демонстрирует сопоставимую точность: разница в метриках составила всего 1.05% по MSE и 0.37% по R2, что подтверждает корректность реализации. При этом custom-реализация оказалась в 1.4 раза медленнее стандартной библиотеки, что объясняется отсутствием низкоуровневых оптимизаций. В процессе подбора гиперпараметров было выявлено, что оптимальная конфигурация включает небольшую глубину деревьев (max_depth=2) и умеренную подвыборку данных (subsample=0.7), что позволило достичь лучших результатов с R2 = 0.7806 и MSE = 0.1370. Это подтверждает важность правильной настройки параметров регуляризации для предотвращения переобучения модели.
