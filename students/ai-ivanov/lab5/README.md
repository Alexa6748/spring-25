# Лабораторная работа №5. Модель латентных факторов (LFM)

## Описание модели латентных факторов

### Теоретические основы

Модель латентных факторов (LFM, Latent Factor Model) является одним из наиболее эффективных подходов для рекомендательных систем. Основная идея модели заключается в том, что рейтинг пользователя можно разложить на несколько компонент:

$$r_{ui} = \mu + b_u + b_i + \sum_{t=1}^{T} p_{ut} \cdot q_{it}$$

где:
- $\mu$ — глобальное среднее значение рейтингов
- $b_u$ — bias пользователя (отражает его строгость/лояльность в оценках)
- $b_i$ — bias объекта (отражает общую популярность/качество объекта)
- $p_{ut}$ — степень интереса пользователя $u$ к латентному фактору $t$
- $q_{it}$ — степень принадлежности объекта $i$ к латентному фактору $t$
- $T$ — количество латентных факторов

### Алгоритм обучения

Для обучения модели используется метод стохастического градиентного спуска (SGD). Целевая функция:

$$\min_{P,Q,b_u,b_i} \sum_{(u,i) \in D} \left( r_{ui} - \hat{r}_{ui} \right)^2 + \lambda \left( \|p_u\|^2 + \|q_i\|^2 + b_u^2 + b_i^2 \right)$$

где $D$ — множество наблюдаемых рейтингов, $\lambda$ — коэффициент регуляризации.

Градиентные шаги для обновления параметров:
- $b_u := b_u + \alpha \cdot (e_{ui} - \lambda \cdot b_u)$
- $b_i := b_i + \alpha \cdot (e_{ui} - \lambda \cdot b_i)$
- $p_{ut} := p_{ut} + \alpha \cdot (e_{ui} \cdot q_{it} - \lambda \cdot p_{ut})$
- $q_{it} := q_{it} + \alpha \cdot (e_{ui} \cdot p_{ut} - \lambda \cdot q_{it})$

где $e_{ui} = r_{ui} - \hat{r}_{ui}$ — ошибка предсказания, $\alpha$ — скорость обучения.

## Описание датасета

В работе использован датасет **Book-Crossing Dataset**, содержащий рейтинги книг от пользователей. Датасет состоит из трех основных файлов:

### Структура данных
- **Books.csv**: Информация о книгах (ISBN, название, автор, год издания, издательство)
- **Users.csv**: Информация о пользователях (ID пользователя, возраст, местоположение)
- **Ratings.csv**: Рейтинги книг (ID пользователя, ISBN, рейтинг от 1 до 10)

### Характеристики датасета
- **Общий размер данных**: 383,856 записей с ненулевыми рейтингами
- **Количество уникальных пользователей**: 68,092
- **Количество уникальных книг**: 149,842
- **Диапазон рейтингов**: 1-10
- **Разделение данных**: 80% для обучения (307,084 записей), 20% для тестирования (76,772 записи)

### Предобработка данных
1. Объединение всех трех датасетов по соответствующим ключам
2. Фильтрация записей с нулевыми рейтингами (неявные оценки)
3. Создание внутренних индексов для пользователей и книг
4. Случайное разделение на тренировочную и тестовую выборки

## Реализация модели

Собственная реализация LFM включает:

### Основные параметры
- `n_factors`: Количество латентных факторов (50)
- `n_epochs`: Количество эпох обучения (20)
- `lr`: Скорость обучения (0.01)
- `reg`: Коэффициент регуляризации (0.02)
- `random_state`: Для воспроизводимости результатов (42)

## Результаты экспериментов

### Собственная реализация LFM

| Метрика | Значение |
|---------|----------|
| **RMSE** | 1.6163 |
| **MAE** | 1.2415 |
| **Время обучения** | 132.51 сек |
| **Время предсказания** | 1.10 сек |
| **Среднее предсказанное значение** | 7.6835 |
| **Среднее истинное значение** | 7.6287 |

## Сравнение с эталонной реализацией

Для сравнения использовалась библиотека **Surprise** с алгоритмом SVD, настроенным с аналогичными параметрами.

### Сравнительная таблица

| Модель | RMSE | MAE | Время обучения (сек) | Время предсказания (сек) |
|--------|------|-----|---------------------|-------------------------|
| **Собственная LFM** | **1.6163** | **1.2415** | 132.51 | 1.10 |
| **Surprise SVD** | 1.6406 | 1.2613 | **2.98** | 1.28 |

### Анализ результатов

Собственная реализация показывает лучшие результаты по качеству предсказаний: RMSE меньше на 0.024, MAE меньше на 0.020. Время предсказания сопоставимо — разница составляет всего 0.18 секунды. Основной недостаток — значительно более медленное обучение, которое занимает в 44.5 раза больше времени.

Различия объясняются тем, что Surprise использует оптимизированные C/Cython реализации для быстрого обучения, тогда как собственная модель написана на Python с NumPy, что обеспечивает более детальную обработку обновлений параметров и лучшее качество.
