
---

# **Отчет по лабораторной работе №1: Ансамбли моделей**

## **1. Описание выбранного метода**

В данной работе реализован ансамблевый метод **бустинга**, а именно его классическая версия, аналогичная алгоритму AdaBoost.

**Суть метода бустинга:**

Бустинг (от англ. *boost* — «усиление») — это метод ансамблирования, при котором несколько слабых моделей (обычно простые модели, например, деревья решений небольшой глубины) последовательно обучаются, и каждая следующая модель пытается исправить ошибки предыдущих.

На каждой итерации:

* Слабый алгоритм обучается на выборке с учетом весов объектов;
* Объекты, которые были неправильно классифицированы, получают больший вес;
* Итоговое решение принимается на основе взвешенного голосования всех слабых моделей.

В работе реализован классический AdaBoost с использованием **однослойных деревьев решений** в качестве базовых моделей.

## **2. Описание датасета**

В качестве исходных данных использовался классический датасет **Iris** из библиотеки `sklearn.datasets`.

### **Характеристики датасета:**

* Количество объектов: 150
* Признаки: 4 числовых признака, описывающих цветок ириса:

  * Длина чашелистика
  * Ширина чашелистика
  * Длина лепестка
  * Ширина лепестка
* Количество классов: 3 вида ирисов:

  * Setosa
  * Versicolor
  * Virginica

### **Преобразование для задачи:**

* Для упрощения задачи произведено преобразование в бинарную классификацию:

  * Класс **Virginica** обозначен как **1**;
  * Остальные классы обозначены как **-1**.

Таким образом, задача сводится к бинарной классификации: "Virginica" против остальных.

## **3. Результаты экспериментов**

### **Собственная реализация бустинга:**

* Количество базовых моделей: 10
* Базовый алгоритм: дерево решений глубиной 1
* Точность на тестовой выборке: **0.9111**
* Время обучения: **0.0064 секунды**

### **Сравнение с библиотечной реализацией (`sklearn.ensemble.AdaBoostClassifier`):**

* Количество базовых моделей: 10
* Базовый алгоритм: дерево решений глубиной 1
* Точность на тестовой выборке: **0.9111**
* Время обучения: **0.0119 секунды**

## **4. Выводы**

* Собственная реализация классического бустинга показала идентичный результат по точности по сравнению с библиотечной реализацией `AdaBoostClassifier` из `sklearn`.
* Время обучения собственной реализации оказалось даже немного ниже, что связано с минималистичной реализацией без дополнительных проверок и оптимизаций, присутствующих в промышленной библиотеке.
* Реализация подтвердила корректность понимания принципов работы бустинга.
* Использование библиотечных решений предпочтительно для реальных задач, поскольку они более оптимизированы, масштабируемы и проверены на большое количество кейсов.

---
