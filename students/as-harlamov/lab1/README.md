# Лабораторная работа №1. Ансамбли моделей

В рамках лабораторной работы предстоит реализовать один из ансамблевых методов на выбор: бустинг, бэггинг или метод случайных подпространств (RSM).

В качестве базовых алгоритмов рекомендуется использовать библиотечные реализации.

## Задание

1. Выбрать датасет для анализа;
2. Реализовать один из следующих ансамблевых методов:
    * Бустинг;
    * Бэггинг;
    * Метод случайных подпространств (RSM);
3. Для выбранного метода:
    * обучить модель на каждом из датасетов;
    * оценить качество модели с использованием кросс-валидации;
    * замерить время обучения модели;
4. Сравнить результаты с эталонными реализациями из библиотеки [scikit-learn](https://scikit-learn.org/stable/):
    * точность модели;
    * время обучения;
5. Подготовить отчет, включающий:
    * описание выбранного метода;
    * описание датасета;
    * результаты экспериментов;
    * сравнение с эталонными реализациями;
    * выводы.

## Решение

1. Для анализа был выбран датасет Iris из библиотеки scikit-learn
2. Для выполнения данной лабораторной работы был выбран метод бэггинга (Bagging). Этот ансамблевый метод основан на создании нескольких независимых моделей, обученных на разных подвыборках данных с возвращением (bootstrap-подвыборки). Результаты всех моделей объединяются путем голосования (для задач классификации) или усреднения (для задач регрессии).
3. Реализация бэггинга представлена в файле [bagging.py](source/bagging.py)

### Сравнение результатов

```
MY BAGGING: 1xDecisionTreeClassifier(max_depth=1, random_state=42)
Время работы: 0.008
Кросс-валидация: 0.127

SKLEARN BAGGING: 1xDecisionTreeClassifier(max_depth=1, random_state=42)
Время работы: 0.012
Кросс-валидация: 0.613

```

```
MY BAGGING: 5xDecisionTreeClassifier(max_depth=1, random_state=42)
Время работы: 0.014
Кросс-валидация: 0.127

SKLEARN BAGGING: 5xDecisionTreeClassifier(max_depth=1, random_state=42)
Время работы: 0.023
Кросс-валидация: 0.953

```

```
MY BAGGING: 10xDecisionTreeClassifier(max_depth=1, random_state=42)
Время работы: 0.019
Кросс-валидация: 0.127

SKLEARN BAGGING: 10xDecisionTreeClassifier(max_depth=1, random_state=42)
Время работы: 0.033
Кросс-валидация: 0.967

```

```
MY BAGGING: 1xDecisionTreeClassifier(max_depth=2, random_state=42)
Время работы: 0.003
Кросс-валидация: 0.927

SKLEARN BAGGING: 1xDecisionTreeClassifier(max_depth=2, random_state=42)
Время работы: 0.007
Кросс-валидация: 0.947

```

```
MY BAGGING: 5xDecisionTreeClassifier(max_depth=2, random_state=42)
Время работы: 0.011
Кросс-валидация: 0.920

SKLEARN BAGGING: 5xDecisionTreeClassifier(max_depth=2, random_state=42)
Время работы: 0.019
Кросс-валидация: 0.947

```

```
MY BAGGING: 10xDecisionTreeClassifier(max_depth=2, random_state=42)
Время работы: 0.019
Кросс-валидация: 0.913

SKLEARN BAGGING: 10xDecisionTreeClassifier(max_depth=2, random_state=42)
Время работы: 0.033
Кросс-валидация: 0.960
```


## Выводы

Реализованный классификатор на основе бэггинга работает в два раза быстрее, чем реализация Sklearn, однако проигрывает в качестве в первых трех экспериментах, где в качестве базовой модели было выбрано дерево принятия решений с глубиной 1. 

Бэггинг является простым методом ассемблирования, однако дает неплохие результаты (это можно заметить по разнице точности в 1x, 5x и 10x) – чем больше моделей, тем выше точность.
