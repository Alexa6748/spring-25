# Лабораторная работа №1. Ансамбли моделей

В рамках лабораторной работы предстоит реализовать один из ансамблевых методов на выбор: бустинг, бэггинг или метод случайных подпространств (RSM).

В качестве базовых алгоритмов рекомендуется использовать библиотечные реализации.

## Задание

1. Выбрать датасет для анализа;
2. Реализовать один из следующих ансамблевых методов:
    * Бустинг;
    * Бэггинг;
    * Метод случайных подпространств (RSM);
3. Для выбранного метода:
    * обучить модель на каждом из датасетов;
    * оценить качество модели с использованием кросс-валидации;
    * замерить время обучения модели;
4. Сравнить результаты с эталонными реализациями из библиотеки [scikit-learn](https://scikit-learn.org/stable/):
    * точность модели;
    * время обучения;
5. Подготовить отчет, включающий:
    * описание выбранного метода;
    * описание датасета;
    * результаты экспериментов;
    * сравнение с эталонными реализациями;
    * выводы.

## Датасет

В качестве датасета был выбран Iris (задача классификация растений ирисов)

## Описание метода решения

Ансмаблевый метод бэггинг:

1. Бутстрэп-выборка (Bootstrap Sampling)
- Из исходного набора данных создаётся несколько подвыборок с повторением (т. е. некоторые объекты могут попасть в выборку несколько раз, а некоторые — ни разу).
- Каждая подвыборка имеет тот же размер, что и исходные данные.

2. Обучение базовых моделей
- На каждой подвыборке обучается отдельная модель (в нашем случае - дерево решений)
- Модели обучаются независимо друг от друга.

3. Агрегация предсказаний
- Метод голосования - выбирается класс, за который проголосовало большинство моделей

### Сравнение результатов

```
MY BAGGING: DecisionTreeClassifier(max_depth=1, random_state=31)
Количество классификаторов: 1
Время работы: 0.007
Доля правильных ответов (кросс-валидация): 0.200

SKLEARN BAGGING: DecisionTreeClassifier(max_depth=1, random_state=31)
Количество классификаторов: 1
Время работы: 0.009
Доля правильных ответов (кросс-валидация): 0.667

MY BAGGING: DecisionTreeClassifier(max_depth=1, random_state=31)
Количество классификаторов: 5
Время работы: 0.012
Доля правильных ответов (кросс-валидация): 0.200

SKLEARN BAGGING: DecisionTreeClassifier(max_depth=1, random_state=31)
Количество классификаторов: 5
Время работы: 0.020
Доля правильных ответов (кросс-валидация): 0.707

MY BAGGING: DecisionTreeClassifier(max_depth=1, random_state=31)
Количество классификаторов: 10
Время работы: 0.022
Доля правильных ответов (кросс-валидация): 0.127

SKLEARN BAGGING: DecisionTreeClassifier(max_depth=1, random_state=31)
Количество классификаторов: 10
Время работы: 0.035
Доля правильных ответов (кросс-валидация): 0.953

MY BAGGING: DecisionTreeClassifier(max_depth=2, random_state=31)
Количество классификаторов: 1
Время работы: 0.004
Доля правильных ответов (кросс-валидация): 0.920

SKLEARN BAGGING: DecisionTreeClassifier(max_depth=2, random_state=31)
Количество классификаторов: 1
Время работы: 0.008
Доля правильных ответов (кросс-валидация): 0.953

MY BAGGING: DecisionTreeClassifier(max_depth=2, random_state=31)
Количество классификаторов: 5
Время работы: 0.012
Доля правильных ответов (кросс-валидация): 0.913

SKLEARN BAGGING: DecisionTreeClassifier(max_depth=2, random_state=31)
Количество классификаторов: 5
Время работы: 0.020
Доля правильных ответов (кросс-валидация): 0.940

MY BAGGING: DecisionTreeClassifier(max_depth=2, random_state=31)
Количество классификаторов: 10
Время работы: 0.022
Доля правильных ответов (кросс-валидация): 0.920

SKLEARN BAGGING: DecisionTreeClassifier(max_depth=2, random_state=31)
Количество классификаторов: 10
Время работы: 0.036
Доля правильных ответов (кросс-валидация): 0.940
```

## Выводы

Написанный мною классификатор работает немного быстрее, чем библиотечная реализация, но уступает в некоторых экспериментах
по точности (в решениях с глубиной дерева = 1).

В экспериментах с глубиной дерева = 2 результат реализованного классификатор сравним с библиотечной реализацией (отличие не более 5%)