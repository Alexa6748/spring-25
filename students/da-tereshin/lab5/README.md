# Лабораторная работа №5. Модель латентных факторов (LFM)

## Датасет 

URL: https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset

Набор данны MovieLens был собран в рамках исследовательского проекта GroupLens
в Университете Миннесоты.

Этот набор данных включает в себя:
* 100 000 оценок (1-5) от 943 пользователей для 1682 фильмов.
* Каждый пользователь оценил не менее 20 фильмов.

Данные были собраны с помощью веб-сайта MovieLens (movielens.umn.edu) в течение семи месяцев с 19 сентября 1997 г. 
по 22 апреля 1998 г, 1997 года по 22 апреля 1998 года. Эти данные были очищены - пользователи, у которых было менее 20 оценок 
или не было полной демографической информации, были удалены из этого набора данных.


## Описание алгоритма
Модель латентных векторов (Latent Factor Model, LFM) — это метод машинного обучения, используемый для рекомендательных
систем и анализа данных. Он основан на представлении объектов (например, пользователей и айтемов) в виде векторов в
скрытом (латентном) пространстве признаков.

SVD – одна из ключевых реализаций SVD, где сингулярное разложение применяется к матрице взаимодействий и в качестве 
латентных векторов берутся сингулярные векторы. При обучении используется метод стохастического градиента с регуляризацией.
При этом минимизируется MSE между предсказанным и истинным значением взаимодействия.


## Результаты обучения

### Время обучения

| Своя реализация, c | Библиотечная реализация, с |
|--------------------|----------------------------|
| 1.17 ± 0.022       | 0.0953 ± 0.007             |


### Качество

<table>
    <thead>
        <tr>
            <th colspan="2">Своя реализация</th>
            <th colspan="2">Библиотечная реализация</th>
        </tr>
        <tr>
            <th>RMSE</th>
            <th>MAE</th>
            <th>RMSE</th>
            <th>MAE</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0.9724</td>
            <td>0.7651</td>
            <td>0.9339</td>
            <td>0.7383</td>
        </tr>
    </tbody>
</table>

## Выводы
Поскольку работа происходила с готовым классом-объектом датасета из библиотеки, то реализация surprise ожидаемо в разы 
быстрее самописной. Кроме того, библиотека реализована на Cython, что также увеличивает разницу в скорости обучения.
Тем не менее, хранения только списка взаимодействий вместо целой матрицы взаимодействий позволило сократить обучение 
самописной реализации до 2 секунд.

Качество обучения в ручной реализации слегка проигрывает библиотечной, поскольку surprise использует более сложный метод
градиентного спуска (например, адаптивный lr и т.д.).