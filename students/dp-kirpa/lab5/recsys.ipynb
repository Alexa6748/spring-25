{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Подключение зависимостей"
      ],
      "metadata": {
        "id": "8k71UMFazkD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "XC8qUcfoM2g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "-uqOQMf9vzIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Данные"
      ],
      "metadata": {
        "id": "Nxkg0NxYzpFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "def download_movielens(size='small', path='./data'):\n",
        "    if size == 'small':\n",
        "        url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "    elif size == '1m':\n",
        "        url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "    elif size == '25m':\n",
        "        url = 'https://files.grouplens.org/datasets/movielens/ml-25m.zip'\n",
        "    elif size == 'latest-full':\n",
        "        url = 'https://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
        "    else:\n",
        "        raise ValueError(\"Размер должен быть 'small', '1m', '25m' или 'latest-full'\")\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    print(f\"Скачивание {url}...\")\n",
        "    r = requests.get(url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(path)\n",
        "    print(f\"Данные сохранены в {path}\")\n",
        "\n",
        "    dataset_dir = [f for f in os.listdir(path) if f.startswith('ml-')][0]\n",
        "    return os.path.join(path, dataset_dir)\n",
        "\n",
        "dataset_path = download_movielens('small')\n",
        "\n",
        "ratings = pd.read_csv(os.path.join(dataset_path, 'ratings.csv'))\n",
        "movies = pd.read_csv(os.path.join(dataset_path, 'movies.csv'))\n",
        "\n",
        "print(f\"Данные о рейтингах: {ratings.shape}\")\n",
        "print(ratings.head())\n",
        "\n",
        "print(f\"Данные о фильмах: {movies.shape}\")\n",
        "print(movies.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9qReSzBfCGx",
        "outputId": "a2d706df-fb80-4d55-d244-3b0977b98810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скачивание https://files.grouplens.org/datasets/movielens/ml-latest-small.zip...\n",
            "Данные сохранены в ./data\n",
            "Данные о рейтингах: (100836, 4)\n",
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "Данные о фильмах: (9742, 3)\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "user_movie_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "ratings_matrix = user_movie_matrix.values\n",
        "\n",
        "X_train, X_test = train_test_split(ratings_matrix, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "iqAA1cGVgq8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LFM"
      ],
      "metadata": {
        "id": "xKyi3jubZ2aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "class LatentFactorModel:\n",
        "    def __init__(self, n_factors=10, learning_rate=0.01, regularization=0.02, n_epochs=100, random_state=None):\n",
        "        self.n_factors = n_factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.regularization = regularization\n",
        "        self.n_epochs = n_epochs\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.user_factors = None\n",
        "        self.item_factors = None\n",
        "        self.global_bias = None\n",
        "        self.user_biases = None\n",
        "        self.item_biases = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        np.random.seed(self.random_state)\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        n_users, n_items = X.shape\n",
        "\n",
        "        self.user_factors = np.random.normal(0, 0.1, (n_users, self.n_factors))\n",
        "        self.item_factors = np.random.normal(0, 0.1, (n_items, self.n_factors))\n",
        "        self.global_bias = np.mean(X[X > 0])\n",
        "        self.user_biases = np.zeros(n_users)\n",
        "        self.item_biases = np.zeros(n_items)\n",
        "\n",
        "        users, items = np.where(X > 0)\n",
        "        n_ratings = len(users)\n",
        "        ratings = X[users, items]\n",
        "\n",
        "        for epoch in range(self.n_epochs):\n",
        "\n",
        "            indices = np.arange(n_ratings)\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for idx in indices:\n",
        "                u, i = users[idx], items[idx]\n",
        "                r = ratings[idx]\n",
        "\n",
        "                prediction = self.global_bias + self.user_biases[u] + self.item_biases[i] + \\\n",
        "                             np.dot(self.user_factors[u], self.item_factors[i])\n",
        "\n",
        "                error = r - prediction\n",
        "\n",
        "                self.user_biases[u] += self.learning_rate * (error - self.regularization * self.user_biases[u])\n",
        "                self.item_biases[i] += self.learning_rate * (error - self.regularization * self.item_biases[i])\n",
        "\n",
        "                user_factor = self.user_factors[u].copy()\n",
        "                item_factor = self.item_factors[i].copy()\n",
        "\n",
        "                self.user_factors[u] += self.learning_rate * (error * item_factor - self.regularization * self.user_factors[u])\n",
        "                self.item_factors[i] += self.learning_rate * (error * user_factor - self.regularization * self.item_factors[i])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        if self.user_factors is None or self.item_factors is None:\n",
        "            raise ValueError(\"Модель должна быть обучена перед предсказанием.\")\n",
        "\n",
        "        n_users, n_items = len(self.user_biases), len(self.item_biases)\n",
        "\n",
        "        predictions = np.zeros((n_users, n_items))\n",
        "        for u in range(n_users):\n",
        "            for i in range(n_items):\n",
        "                predictions[u, i] = self.global_bias + self.user_biases[u] + self.item_biases[i] + \\\n",
        "                                   np.dot(self.user_factors[u], self.item_factors[i])\n",
        "\n",
        "        if X is not None:\n",
        "            X = np.asarray(X)\n",
        "            mask = X > 0\n",
        "            predictions = predictions * mask\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def factorize(self, X):\n",
        "        self.fit(X)\n",
        "        return self.user_factors, self.item_factors.T\n",
        "\n",
        "    def reconstruct(self):\n",
        "        if self.user_factors is None or self.item_factors is None:\n",
        "            raise ValueError(\"Модель должна быть обучена перед реконструкцией.\")\n",
        "\n",
        "        return self.predict()\n",
        "\n",
        "\n",
        "def compare_lfm_with_sklearn(X, n_factors=10, random_state=42):\n",
        "    X = np.asarray(X)\n",
        "\n",
        "    X_nmf = X.copy()\n",
        "    X_nmf[X_nmf == 0] = 0.001\n",
        "\n",
        "    lfm = LatentFactorModel(n_factors=n_factors, n_epochs=100, random_state=random_state)\n",
        "    lfm.fit(X)\n",
        "    X_pred_lfm = lfm.predict()\n",
        "\n",
        "    nmf = NMF(n_components=n_factors, init='random', random_state=random_state)\n",
        "    W = nmf.fit_transform(X_nmf)\n",
        "    H = nmf.components_\n",
        "    X_pred_nmf = np.dot(W, H)\n",
        "\n",
        "    mask = X > 0\n",
        "\n",
        "    rmse_lfm = np.sqrt(mean_squared_error(X[mask], X_pred_lfm[mask]))\n",
        "    rmse_nmf = np.sqrt(mean_squared_error(X[mask], X_pred_nmf[mask]))\n",
        "\n",
        "    results = {\n",
        "        'LFM RMSE': rmse_lfm,\n",
        "        'NMF RMSE': rmse_nmf,\n",
        "        'LFM Factors': (lfm.user_factors, lfm.item_factors),\n",
        "        'NMF Factors': (W, H)\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "results = compare_lfm_with_sklearn(X_train, n_factors=2)\n",
        "print(f\"LFM RMSE: {results['LFM RMSE']:.4f}\")\n",
        "print(f\"NMF RMSE: {results['NMF RMSE']:.4f}\")"
      ],
      "metadata": {
        "id": "sHXZiWHsQ5lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8555e81e-e9c7-4e82-884e-cb7de6b2d358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LFM RMSE: 0.6937\n",
            "NMF RMSE: 2.9584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lfm = LatentFactorModel(n_factors=20, n_epochs=100, learning_rate=0.01)\n",
        "lfm.fit(X_train)\n",
        "\n",
        "predictions = lfm.predict()"
      ],
      "metadata": {
        "id": "ycbq8bcCfJ6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuCLCZv3gm8V",
        "outputId": "3cd996ce-4fe7-427d-c32a-b24c81202e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.99307945, 3.15538604, 3.67779218, ..., 3.33350566, 3.35190249,\n",
              "        3.60892135],\n",
              "       [3.47012571, 2.9206854 , 2.08414766, ..., 3.35063775, 3.26463128,\n",
              "        3.52633595],\n",
              "       [4.20436986, 2.78399507, 3.26666658, ..., 2.98835837, 3.17860067,\n",
              "        3.32314358],\n",
              "       ...,\n",
              "       [3.81638185, 3.61291281, 3.39220153, ..., 3.08097826, 2.90646414,\n",
              "        3.02011146],\n",
              "       [3.99341281, 3.45360792, 2.61466522, ..., 3.33895097, 2.93222456,\n",
              "        3.63184951],\n",
              "       [3.65841988, 3.92230841, 4.03135212, ..., 3.73231613, 3.88081667,\n",
              "        4.29287422]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}