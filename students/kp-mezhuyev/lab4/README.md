# Отчет по лабораторной работе

## Описание алгоритма
**Латентное размещение Дирихле (LDA)** — это генеративная вероятностная модель для коллекций дискретных данных, таких как текстовые корпуса. LDA предполагает, что каждый документ представляет собой смесь тем, а каждая тема характеризуется распределением над словами.

LDA основана на следующих предположениях:

1. **Количество тем K** фиксировано
2. **Каждая тема k** характеризуется распределением ф_z над словарем
3. **Каждый документ d** характеризуется распределением θ_d над темами
4. **Каждое слово** генерируется в два этапа:
   - Выбирается тема z согласно θ_d
   - Выбирается слово w согласно φ_z

**Гиперпараметры:**
- α (alpha) — параметр распределения Дирихле для тем в документах
- β (beta) — параметр распределения Дирихле для слов в темах


Для вывода скрытых переменных используется **Collapsed Gibbs Sampling**:

P(z_i = k | остальное) ∝ P(w_i|k) × P(k|d_i)

где:

P(w_i|k) = (n_kw + β) / (n_k + V×β)

P(k|d_i) = (n_dk + α) / (n_d + K×α)

## Описание датасета
Источник данных
- **Название**: 20 Newsgroups Dataset
- **Источник**: Kaggle (nandaprasetia/csv-200-20newsgroups)
- **Тип**: Коллекция текстов новостных групп

Характеристики датасета
- **Количество документов**: 7888
- **Количество категорий**: 20
- **Минимум документов в категории**: 217
- **Максимум документов в категории**: 468
- **Соотношение макс/мин**: 2.2

Категории новостных групп
- Компьютерные темы: comp.graphics, comp.os.ms-windows.misc, comp.sys.ibm.pc.hardware
- Рекреационные: rec.autos, rec.motorcycles, rec.sport.baseball, rec.sport.hockey
- Научные: sci.crypt, sci.electronics, sci.med, sci.space
- Социальные: soc.religion.christian
- Политические: talk.politics.guns, talk.politics.mideast, talk.politics.misc
- Религиозные: talk.religion.misc, alt.atheism
- Разное: misc.forsale

Предобработка данных

1. **Очистка текста**: удаление тегов, специальных символов, цифр
2. **Токенизация**: разбиение на отдельные слова
3. **Нормализация**: приведение к нижнему регистру
4. **Удаление стоп-слов**: исключение частых незначимых слов
5. **Лемматизация**: приведение к начальной форме
6. **Фильтрация словаря**:
   - Минимальная частота: 5 вхождений
   - Максимальная частота документов: 50%
   - **Результат**: 6,995 слов (из 32,354 исходных)

## Результаты экспериментов

### Параметры эксперимента

| Параметр | Значение |
|----------|----------|
| Количество тем (K) | 20 |
| Количество итераций (поиск) | 50 |
| Количество итераций (финальное) | 100 |
| Random state | 42 |
| Размер датасета | 7,888 документов |
| Размер словаря | 6,995 слов |
| Всего слов для обработки | 263,119 |

### Поиск оптимальных гиперпараметров
Был проведен полный grid search параметров alpha (концентрация тем в документах) и beta (концентрация слов в темах) среди 20 комбинаций с 2-fold кросс-валидацией:
Параметры поиска:
Alpha: [0.1, 0.5, 1.0, 2.0, 5.0]
Beta: [0.01, 0.1, 0.5, 1.0]
Общее время grid search: ~ 2 часа
Всего обучений: 40 (20 комбинаций × 2 fold)

**Выбранные оптимальные параметры**: alpha=0.1, beta=1.0 (когерентность 1.2939)

### Финальные результаты

#### Производительность
- **Время обучения**: 758.91 секунд
- **Финальная когерентность**: 1.5626
- **Стандартное отклонение когерентности**: 1.2330
- **Улучшение от grid search к финальному**: +0.2687

#### Когерентность по темам:

- Тема 0: 2.591
- Тема 1: 3.671
- Тема 2: 2.315
- Тема 3: 2.716
- Тема 4: 4.375 (максимум)
- Тема 5: 0.371
- Тема 6: 0.323
- Тема 7: 2.418
- Тема 8: 0.555
- Тема 9: 0.587
- Тема 10: 0.450
- Тема 11: 1.324
- Тема 12: 0.878
- Тема 13: 0.323
- Тема 14: 0.246 (минимум)
- Тема 15: 0.939
- Тема 16: 2.135
- Тема 17: 3.122
- Тема 18: 1.469
- Тема 19: 0.445

## Сравнение с эталонной реализацией

Для честного сравнения обе модели обучались с одинаковыми оптимальными параметрами:
- alpha=0.1, beta=1.0
- 100 итераций
- random_state=42

### Когерентность
- CustomLDA - Средняя когерентность: 1.5626
- Sklearn - Средняя когерентность: 2.2305
- Разница: 0.6679

### Время обучения (сек)
- CustomLDA: 758.91
- Sklearn: 43.00     
- Разница: sklearn в 17.6x быстрее

## Выводы
### Производительность
- Sklearn значительно превосходит по скорости обучения (в 17.6 раза быстрее)
- Sklearn показывает лучшее качество тем (когерентность 2.23 vs 1.56)
- Grid search занял 1.9 часа для поиска оптимальных параметров

### Оптимальные параметры
- alpha=0.1: документы специализируются на небольшом количестве тем
- beta=1.0: темы включают широкий спектр слов (менее специализированы)
- Такая комбинация дает наилучший баланс между специализацией документов и разнообразием тем

### Реализация
- Собственная реализация работает корректно
- Необходима дальнейшая оптимизация для конкуренции со sklearn

### Практическое применение
- Для исследовательских целей: CustomLDA позволяет контролировать все аспекты алгоритма
- Для продуктивного использования: sklearn предпочтительнее из-за скорости и качества