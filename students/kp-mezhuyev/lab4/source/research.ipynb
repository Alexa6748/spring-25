{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4. Латентное размещение Дирихле\n",
    "\n",
    "В рамках данной лабораторной работы предстоит реализовать алгоритм латентного размещения Дирихле (LDA) и сравнить его с эталонной реализацией из библиотеки `scikit-learn`.\n",
    "\n",
    "## Задание\n",
    "\n",
    "1. Выбрать текстовый датасет для анализа, например, на [kaggle](https://www.kaggle.com/datasets).\n",
    "2. Реализовать алгоритм латентного размещения Дирихле.\n",
    "3. Обучить модель на выбранном датасете.\n",
    "4. Оценить качество модели с использованием метрик когерентности тем.\n",
    "5. Замерить время обучения модели.\n",
    "6. Сравнить результаты с эталонной реализацией из библиотеки [scikit-learn](https://scikit-learn.org/stable/):\n",
    "   * когерентность тем;\n",
    "   * время обучения.\n",
    "7. Подготовить отчет, включающий:\n",
    "   * описание алгоритма латентного размещения Дирихле;\n",
    "   * описание датасета;\n",
    "   * результаты экспериментов;\n",
    "   * сравнение с эталонной реализацией;\n",
    "   * выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Выбрать текстовый датасет для анализа, например, на [kaggle](https://www.kaggle.com/datasets)\n",
    "### В качестве датасета был выбран набор данных для тематического моделирования\n",
    "\n",
    "### Ссылка:\n",
    "\n",
    "https://www.kaggle.com/datasets/nandaprasetia/csv-200-20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\klimm\\.cache\\kagglehub\\datasets\\nandaprasetia\\csv-200-20newsgroups\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nandaprasetia/csv-200-20newsgroups\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7889, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train200.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "documents      0\n",
       "labels         0\n",
       "label_names    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['documents', 'labels', 'label_names'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_col = 'documents'\n",
    "labels_col = 'labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество документов: 7889\n",
      "Количество уникальных категорий: 20\n",
      "Распределение по категориям:\n",
      "  0:  332 документов - alt.atheism\n",
      "  1:  464 документов - comp.graphics\n",
      "  2:  453 документов - comp.os.ms-windows.misc\n",
      "  3:  468 документов - comp.sys.ibm.pc.hardware\n",
      "  4:  454 документов - comp.sys.mac.hardware\n",
      "  5:  457 документов - comp.windows.x\n",
      "  6:  468 документов - misc.forsale\n",
      "  7:  441 документов - rec.autos\n",
      "  8:  433 документов - rec.motorcycles\n",
      "  9:  416 документов - rec.sport.baseball\n",
      "  10:  403 документов - rec.sport.hockey\n",
      "  11:  363 документов - sci.crypt\n",
      "  12:  462 документов - sci.electronics\n",
      "  13:  407 документов - sci.med\n",
      "  14:  417 документов - sci.space\n",
      "  15:  315 документов - soc.religion.christian\n",
      "  16:  348 документов - talk.politics.guns\n",
      "  17:  290 документов - talk.politics.mideast\n",
      "  18:  281 документов - talk.politics.misc\n",
      "  19:  217 документов - talk.religion.misc\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сбалансированность категорий:\n",
      "  Минимум документов в категории: 217\n",
      "  Максимум документов в категории: 468\n",
      "  Соотношение макс/мин: 2.2\n"
     ]
    }
   ],
   "source": [
    "if labels_col in df.columns:\n",
    "    label_counts = df[labels_col].value_counts().sort_index()\n",
    "    print(f\"Общее количество документов: {len(df)}\")\n",
    "    print(f\"Количество уникальных категорий: {df[labels_col].nunique()}\")\n",
    "    \n",
    "    print(\"Распределение по категориям:\")\n",
    "    for label, count in label_counts.items():\n",
    "        label_name = df[df[labels_col] == label]['label_names'].iloc[0]\n",
    "        print(f\"  {label}: {count:4d} документов - {label_name}\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    label_counts.plot(kind='bar')\n",
    "    plt.title('Распределение документов по категориям')\n",
    "    plt.xlabel('Категория')\n",
    "    plt.ylabel('Количество документов')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Проверка сбалансированности\n",
    "    min_docs = label_counts.min()\n",
    "    max_docs = label_counts.max()\n",
    "    print(f\"\\nСбалансированность категорий:\")\n",
    "    print(f\"  Минимум документов в категории: {min_docs}\")\n",
    "    print(f\"  Максимум документов в категории: {max_docs}\")\n",
    "    print(f\"  Соотношение макс/мин: {max_docs/min_docs:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет неплохо сбалансирован, соотношение приемлимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\klimm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\klimm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\klimm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\klimm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Документов до предобработки: 7889\n",
      "Документов после предобработки: 7888\n",
      "\n",
      "Пример предобработки:\n",
      "Исходный текст:\n",
      "I was wondering if anyone out there could enlighten me on this car I saw the other day. It was a 2door sports car, looked to be from the late 60s early 70s. It was called a Bricklin. The doors were re ...\n",
      "\n",
      "Обработанный текст:\n",
      "wondering anyone could enlighten car saw day door sport car looked late early called bricklin door really small addition front bumper separate rest body know anyone tellme model name engine spec year  ...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Предобработка одного документа для LDA\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление URL, email, специальных символов\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Удаление коротких слов\n",
    "    tokens = [token for token in tokens if len(token) >= 3]\n",
    "    \n",
    "    # Лемматизация\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Применяем предобработку\n",
    "df['processed_text'] = df[documents_col].apply(preprocess_text)\n",
    "\n",
    "# Удаляем пустые документы\n",
    "df_clean = df[df['processed_text'].str.len() > 10].copy()\n",
    "print(f\"Документов до предобработки: {len(df)}\")\n",
    "print(f\"Документов после предобработки: {len(df_clean)}\")\n",
    "\n",
    "# Показываем пример\n",
    "print(\"\\nПример предобработки:\")\n",
    "print(\"Исходный текст:\")\n",
    "print(df[documents_col].iloc[0][:200], \"...\")\n",
    "print(\"\\nОбработанный текст:\")\n",
    "print(df_clean['processed_text'].iloc[0][:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего документов: 7888\n",
      "Уникальных слов до фильтрации: 32354\n",
      "Слов в словаре после фильтрации: 6995\n",
      "Документов в корпусе: 7888\n",
      "\n",
      "Примеры словаря:\n",
      "  0: wondering\n",
      "  1: anyone\n",
      "  2: could\n",
      "  3: enlighten\n",
      "  4: car\n",
      "  5: saw\n",
      "  6: day\n",
      "  7: door\n",
      "  8: sport\n",
      "  9: looked\n",
      "\n",
      "Пример документа (BOW):\n",
      "Первые 20 слов документа:\n",
      "wondering: 1\n",
      "anyone: 2\n",
      "could: 1\n",
      "enlighten: 1\n",
      "car: 4\n",
      "saw: 1\n",
      "day: 1\n",
      "door: 2\n",
      "sport: 1\n",
      "looked: 1\n",
      "late: 1\n",
      "early: 1\n",
      "called: 1\n",
      "really: 1\n",
      "small: 1\n",
      "addition: 1\n",
      "front: 1\n",
      "bumper: 1\n",
      "separate: 1\n",
      "rest: 1\n"
     ]
    }
   ],
   "source": [
    "def create_dictionary_and_corpus(documents):\n",
    "    \"\"\"Создает словарь и корпус для LDA\"\"\"\n",
    "    \n",
    "    # Токенизация документов\n",
    "    tokenized_docs = [doc.split() for doc in documents]\n",
    "    print(f\"Всего документов: {len(tokenized_docs)}\")\n",
    "    \n",
    "    # Подсчет частоты слов\n",
    "    word_freq = defaultdict(int)\n",
    "    doc_freq = defaultdict(int)\n",
    "    \n",
    "    for doc in tokenized_docs:\n",
    "        unique_words = set(doc)\n",
    "        for word in doc:\n",
    "            word_freq[word] += 1\n",
    "        for word in unique_words:\n",
    "            doc_freq[word] += 1\n",
    "    \n",
    "    print(f\"Уникальных слов до фильтрации: {len(word_freq)}\")\n",
    "    \n",
    "    # Фильтрация слов\n",
    "    min_freq = 5        # слово должно встречаться минимум 5 раз\n",
    "    max_doc_ratio = 0.5 # слово не должно быть в >50% документов\n",
    "    n_docs = len(tokenized_docs)\n",
    "    \n",
    "    # Создание словаря\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    current_id = 0\n",
    "    \n",
    "    for word, freq in word_freq.items():\n",
    "        doc_ratio = doc_freq[word] / n_docs\n",
    "        if freq >= min_freq and doc_ratio <= max_doc_ratio:\n",
    "            word_to_id[word] = current_id\n",
    "            id_to_word[current_id] = word\n",
    "            current_id += 1\n",
    "    \n",
    "    print(f\"Слов в словаре после фильтрации: {len(word_to_id)}\")\n",
    "    \n",
    "    # Создание корпуса (bag-of-words)\n",
    "    corpus = []\n",
    "    for doc in tokenized_docs:\n",
    "        doc_bow = [0] * len(word_to_id)\n",
    "        for word in doc:\n",
    "            if word in word_to_id:\n",
    "                doc_bow[word_to_id[word]] += 1\n",
    "        # Пропускаем документы без слов из словаря\n",
    "        if sum(doc_bow) > 0:\n",
    "            corpus.append(doc_bow)\n",
    "    \n",
    "    print(f\"Документов в корпусе: {len(corpus)}\")\n",
    "    return word_to_id, id_to_word, corpus\n",
    "\n",
    "# Создаем словарь и корпус\n",
    "documents = df_clean['processed_text'].tolist()\n",
    "word_to_id, id_to_word, corpus = create_dictionary_and_corpus(documents)\n",
    "\n",
    "# Показываем примеры\n",
    "print(\"\\nПримеры словаря:\")\n",
    "sample_words = list(word_to_id.items())[:10]\n",
    "for word, word_id in sample_words:\n",
    "    print(f\"{word_id:3d}: {word}\")\n",
    "\n",
    "print(\"\\nПример документа (BOW):\")\n",
    "print(\"Первые 20 слов документа:\")\n",
    "doc_example = corpus[0][:20]\n",
    "for i, count in enumerate(doc_example):\n",
    "    if count > 0:\n",
    "        print(f\"{id_to_word[i]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Реализовать алгоритм латентного размещения Дирихле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLDA:\n",
    "    \"\"\"\n",
    "    Собственная реализация LDA с сэмплированием Гиббса\n",
    "    \"\"\"\n",
    "    def __init__(self, n_topics, alpha=0.1, beta=0.01, n_iterations=100, random_state=42):\n",
    "        self.n_topics = n_topics\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    def fit(self, corpus, vocabulary):\n",
    "        \"\"\"Обучение\"\"\"\n",
    "        self.vocabulary = vocabulary\n",
    "        self.V = len(vocabulary)\n",
    "        self.D = len(corpus)\n",
    "        \n",
    "        print(f\"Документов: {self.D}\")\n",
    "        print(f\"Словарь: {self.V} слов\")\n",
    "        print(f\"Тем: {self.n_topics}\")\n",
    "        \n",
    "        # Векторизованная инициализация\n",
    "        self._vectorized_initialize(corpus)\n",
    "        \n",
    "        # Предвычисляем константы для ускорения\n",
    "        self.alpha_sum = self.n_topics * self.alpha\n",
    "        self.beta_sum = self.V * self.beta\n",
    "        \n",
    "        # Сэмплирование\n",
    "        for iteration in range(self.n_iterations):\n",
    "            if iteration % 20 == 0:\n",
    "                print(f\"Итерация {iteration}/{self.n_iterations}\")\n",
    "            self._vectorized_gibbs_sampling()\n",
    "\n",
    "        # Векторизованные финальные распределения\n",
    "        self._vectorized_compute_distributions()\n",
    "        \n",
    "    def _vectorized_initialize(self, corpus):\n",
    "        \"\"\"Инициализация\"\"\"\n",
    "        \n",
    "        # Преобразуем в плоские массивы\n",
    "        self.words = []\n",
    "        self.docs = []\n",
    "        self.topics = []\n",
    "        \n",
    "        total_words = 0\n",
    "        for doc_id, doc_bow in enumerate(corpus):\n",
    "            for word_id, count in enumerate(doc_bow):\n",
    "                if count > 0:  # Пропускаем нулевые счетчики\n",
    "                    # Добавляем все вхождения слова\n",
    "                    self.words.extend([word_id] * count)\n",
    "                    self.docs.extend([doc_id] * count)\n",
    "                    # Случайные темы\n",
    "                    random_topics = np.random.randint(0, self.n_topics, count)\n",
    "                    self.topics.extend(random_topics)\n",
    "                    total_words += count\n",
    "        \n",
    "        # Конвертируем в numpy для быстрых операций\n",
    "        self.words = np.array(self.words, dtype=np.int32)\n",
    "        self.docs = np.array(self.docs, dtype=np.int32)\n",
    "        self.topics = np.array(self.topics, dtype=np.int32)\n",
    "        \n",
    "        print(f\"Всего слов для обработки: {total_words}\")\n",
    "        \n",
    "        # Инициализируем счетчики\n",
    "        self.n_dk = np.zeros((self.D, self.n_topics), dtype=np.int32)\n",
    "        self.n_kw = np.zeros((self.n_topics, self.V), dtype=np.int32)\n",
    "        self.n_k = np.zeros(self.n_topics, dtype=np.int32)\n",
    "        self.n_d = np.zeros(self.D, dtype=np.int32)\n",
    "        \n",
    "        # Заполнение счетчиков\n",
    "        np.add.at(self.n_dk, (self.docs, self.topics), 1)\n",
    "        np.add.at(self.n_kw, (self.topics, self.words), 1)\n",
    "        np.add.at(self.n_k, self.topics, 1)\n",
    "        np.add.at(self.n_d, self.docs, 1)\n",
    "        \n",
    "    def _vectorized_gibbs_sampling(self):\n",
    "        \"\"\"Сэмплирование Гиббса\"\"\"\n",
    "        # Обрабатываем все слова последовательно\n",
    "        for i in range(len(self.words)):\n",
    "            w = self.words[i]\n",
    "            d = self.docs[i]\n",
    "            k_old = self.topics[i]\n",
    "            \n",
    "            # Убираем текущее назначение\n",
    "            self.n_dk[d, k_old] -= 1\n",
    "            self.n_kw[k_old, w] -= 1\n",
    "            self.n_k[k_old] -= 1\n",
    "            \n",
    "            # Вычисление вероятностей для всех тем\n",
    "            # P(w|k) для всех тем\n",
    "            p_w_given_k = (self.n_kw[:, w] + self.beta) / (self.n_k + self.beta_sum)\n",
    "            \n",
    "            # P(k|d) для всех тем\n",
    "            p_k_given_d = (self.n_dk[d, :] + self.alpha) / (self.n_d[d] - 1 + self.alpha_sum)\n",
    "            \n",
    "            # Итоговые вероятности\n",
    "            p_k = p_w_given_k * p_k_given_d\n",
    "            \n",
    "            # Нормализация\n",
    "            p_k = p_k / np.sum(p_k)\n",
    "            \n",
    "            # Сэмплирование новой темы\n",
    "            k_new = np.random.choice(self.n_topics, p=p_k)\n",
    "            self.topics[i] = k_new\n",
    "            \n",
    "            # Обновляем счетчики\n",
    "            self.n_dk[d, k_new] += 1\n",
    "            self.n_kw[k_new, w] += 1\n",
    "            self.n_k[k_new] += 1\n",
    "    \n",
    "    def _vectorized_compute_distributions(self):\n",
    "        \"\"\"Вычисление распределений\"\"\"\n",
    "        \n",
    "        # распределение тем в документах\n",
    "        self.theta = (self.n_dk + self.alpha) / (self.n_d[:, np.newaxis] + self.alpha_sum)\n",
    "        \n",
    "        # распределение слов в темах\n",
    "        self.phi = (self.n_kw + self.beta) / (self.n_k[:, np.newaxis] + self.beta_sum)\n",
    "    \n",
    "    def get_top_words(self, topic_id, n_words=10):\n",
    "        \"\"\"Получить топ-слова для темы\"\"\"\n",
    "\n",
    "        word_probs = self.phi[topic_id]\n",
    "        top_words_ids = np.argsort(word_probs)[::-1][:n_words]\n",
    "        top_words = [(self.vocabulary[word_id], word_probs[word_id]) \n",
    "                     for word_id in top_words_ids]\n",
    "        return top_words\n",
    "    \n",
    "    def print_topics(self, n_words=8):\n",
    "        \"\"\"Вывод тем с топ-словами\"\"\"\n",
    "        print(\"\\nТемы:\")\n",
    "        for k in range(self.n_topics):\n",
    "            top_words = self.get_top_words(k, n_words)\n",
    "            words_str = ', '.join([f\"{word}\" for word, prob in top_words])\n",
    "            print(f\"Тема {k:2d}: {words_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-5. Обучить модель на выбранном датасете, оценить качество модели с использованием метрик когерентности тем, замерить время обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск оптимальных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_coherence(lda_model, corpus_texts, n_words=10, verbose=True):\n",
    "    \"\"\"\n",
    "    Вычисляет когерентность тем на основе совместной встречаемости слов\n",
    "    \n",
    "    lda_model: обученная модель LDA\n",
    "    corpus_texts: список обработанных текстов\n",
    "    n_words: количество топ-слов для анализа\n",
    "    verbose: выводить ли информацию о первых 5 темах (по умолчанию True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Получаем все темы\n",
    "    all_topics = []\n",
    "    for k in range(lda_model.n_topics):\n",
    "        top_words = lda_model.get_top_words(k, n_words)\n",
    "        topic_words = [word for word, prob in top_words]\n",
    "        all_topics.append(topic_words)\n",
    "    \n",
    "    # Вычисляем когерентность для каждой темы\n",
    "    topic_coherences = []\n",
    "    \n",
    "    for topic_id, topic_words in enumerate(all_topics):\n",
    "        coherence_scores = []\n",
    "        \n",
    "        # Для каждой пары слов в теме\n",
    "        for i in range(len(topic_words)):\n",
    "            for j in range(i + 1, len(topic_words)):\n",
    "                word1, word2 = topic_words[i], topic_words[j]\n",
    "                \n",
    "                # Считаем совместную встречаемость\n",
    "                co_occurrence = 0\n",
    "                word1_count = 0\n",
    "                word2_count = 0\n",
    "                \n",
    "                for doc in corpus_texts:\n",
    "                    has_word1 = word1 in doc\n",
    "                    has_word2 = word2 in doc\n",
    "                    \n",
    "                    if has_word1:\n",
    "                        word1_count += 1\n",
    "                    if has_word2:\n",
    "                        word2_count += 1\n",
    "                    if has_word1 and has_word2:\n",
    "                        co_occurrence += 1\n",
    "                \n",
    "                # Вычисляем PMI (Pointwise Mutual Information)\n",
    "                if co_occurrence > 0 and word1_count > 0 and word2_count > 0:\n",
    "                    pmi = np.log((co_occurrence * len(corpus_texts)) / \n",
    "                                (word1_count * word2_count))\n",
    "                    coherence_scores.append(pmi)\n",
    "        \n",
    "        # Средняя когерентность для темы\n",
    "        if coherence_scores:\n",
    "            topic_coherence = np.mean(coherence_scores)\n",
    "        else:\n",
    "            topic_coherence = 0\n",
    "            \n",
    "        topic_coherences.append(topic_coherence)\n",
    "        \n",
    "        # Показываем детали для первых 5 тем\n",
    "        if verbose and topic_id < 5:\n",
    "            words_str = ', '.join(topic_words[:5])\n",
    "            print(f\"Тема {topic_id:2d}: {topic_coherence:6.3f} - {words_str}\")\n",
    "\n",
    "    overall_coherence = np.mean(topic_coherences)        \n",
    "    return overall_coherence, topic_coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_texts = df_clean['processed_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAWrapper(BaseEstimator):\n",
    "    \"\"\"Обертка для CustomLDA, совместимая с sklearn GridSearchCV\"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.1, beta=0.01, n_topics=20, n_iterations=50, random_state=42):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_topics = n_topics\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        self.lda_model = None\n",
    "        self.training_time = 0\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Обучение модели\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.lda_model = CustomLDA(\n",
    "            n_topics=self.n_topics,\n",
    "            alpha=self.alpha,\n",
    "            beta=self.beta,\n",
    "            n_iterations=self.n_iterations,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        self.lda_model.fit(X, id_to_word)\n",
    "        self.training_time = time.time() - start_time\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        \"\"\"Возвращает когерентность как метрику качества\"\"\"\n",
    "        if self.lda_model is None:\n",
    "            return -float('inf')\n",
    "        \n",
    "        coherence, _ = calculate_topic_coherence(self.lda_model, corpus_texts, verbose=False)\n",
    "        return coherence\n",
    "    \n",
    "    def get_coherence_details(self, verbose=True):\n",
    "        \"\"\"Получить детальную информацию о когерентности\"\"\"\n",
    "        if self.lda_model is None:\n",
    "            return None, None\n",
    "        return calculate_topic_coherence(self.lda_model, corpus_texts, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем поиск лучших параметров\n",
      "Параметры для поиска:\n",
      "Alpha: [0.1, 0.5, 1.0, 2.0, 5.0]\n",
      "Beta: [0.01, 0.1, 0.5, 1.0]\n",
      "Всего комбинаций: 20\n",
      "\n",
      "Начинаем GridSearch...\n",
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=0.1, beta=0.01; total time= 3.6min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=0.1, beta=0.01; total time= 3.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.1, beta=0.1; total time= 3.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.1, beta=0.1; total time= 3.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.1, beta=0.5; total time= 3.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.1, beta=0.5; total time= 3.4min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.1, beta=1.0; total time= 2.6min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.1, beta=1.0; total time= 2.0min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=0.5, beta=0.01; total time= 2.4min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=0.5, beta=0.01; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.5, beta=0.1; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.5, beta=0.1; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.5, beta=0.5; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.5, beta=0.5; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.5, beta=1.0; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=0.5, beta=1.0; total time= 2.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=1.0, beta=0.01; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=1.0, beta=0.01; total time= 2.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=1.0, beta=0.1; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=1.0, beta=0.1; total time= 2.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=1.0, beta=0.5; total time= 2.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=1.0, beta=0.5; total time= 2.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=1.0, beta=1.0; total time= 2.3min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=1.0, beta=1.0; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=2.0, beta=0.01; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=2.0, beta=0.01; total time= 2.3min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=2.0, beta=0.1; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=2.0, beta=0.1; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=2.0, beta=0.5; total time= 2.2min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=2.0, beta=0.5; total time= 2.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=2.0, beta=1.0; total time= 2.4min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=2.0, beta=1.0; total time= 2.9min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=5.0, beta=0.01; total time= 3.9min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ...............................alpha=5.0, beta=0.01; total time= 3.9min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=5.0, beta=0.1; total time= 3.8min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=5.0, beta=0.1; total time= 3.9min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=5.0, beta=0.5; total time= 4.0min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=5.0, beta=0.5; total time= 3.9min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 132278\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=5.0, beta=1.0; total time= 4.1min\n",
      "Документов: 3944\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 130841\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "[CV] END ................................alpha=5.0, beta=1.0; total time= 3.4min\n",
      "Документов: 7888\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 263119\n",
      "Итерация 0/50\n",
      "Итерация 20/50\n",
      "Итерация 40/50\n",
      "\n",
      "GridSearch завершен за 6990.58 секунд\n",
      "Результаты GridSearch\n",
      "Лучшие параметры: alpha=0.1, beta=1.0\n",
      "Лучшая когерентность: 1.2939\n",
      "\n",
      "Все результаты (отсортированы по когерентности):\n",
      "1. alpha=0.1, beta=1.0: когерентность=1.2939\n",
      "2. alpha=0.1, beta=0.5: когерентность=0.8029\n",
      "3. alpha=0.5, beta=1.0: когерентность=0.7968\n",
      "4. alpha=1.0, beta=1.0: когерентность=0.5332\n",
      "5. alpha=0.5, beta=0.5: когерентность=0.5328\n",
      "6. alpha=1.0, beta=0.5: когерентность=0.4926\n",
      "7. alpha=0.5, beta=0.1: когерентность=0.4830\n",
      "8. alpha=0.1, beta=0.1: когерентность=0.4790\n",
      "9. alpha=1.0, beta=0.1: когерентность=0.4511\n",
      "10. alpha=2.0, beta=0.1: когерентность=0.4243\n",
      "11. alpha=2.0, beta=0.5: когерентность=0.4095\n",
      "12. alpha=0.5, beta=0.01: когерентность=0.3988\n",
      "13. alpha=0.1, beta=0.01: когерентность=0.3972\n",
      "14. alpha=2.0, beta=1.0: когерентность=0.3481\n",
      "15. alpha=1.0, beta=0.01: когерентность=0.3464\n",
      "16. alpha=2.0, beta=0.01: когерентность=0.3400\n",
      "17. alpha=5.0, beta=0.1: когерентность=0.3345\n",
      "18. alpha=5.0, beta=0.5: когерентность=0.3146\n",
      "19. alpha=5.0, beta=0.01: когерентность=0.2787\n",
      "20. alpha=5.0, beta=1.0: когерентность=0.2209\n",
      "Финальное обучение с лучшими параметрами\n",
      "Обучаем с лучшими параметрами: alpha=0.1, beta=1.0\n",
      "Увеличиваем итерации до 100 для максимального качества\n",
      "Документов: 7888\n",
      "Словарь: 6995 слов\n",
      "Тем: 20\n",
      "Всего слов для обработки: 263119\n",
      "Итерация 0/100\n",
      "Итерация 20/100\n",
      "Итерация 40/100\n",
      "Итерация 60/100\n",
      "Итерация 80/100\n",
      "Финальное обучение завершено за 758.91 секунд\n",
      "\n",
      "Темы:\n",
      "Тема  0: msg, food, chinese, turkey, reaction, film, study, methanol\n",
      "Тема  1: internet, everywhere, phone, corp, uucp, ssdnetworking, medin, office\n",
      "Тема  2: cub, suck, bob, sea, stay, could, bronx, blew\n",
      "Тема  3: thrush, contact, prevent, tube, spray, ovule, actually, vasomotor\n",
      "Тема  4: bank, soon, surrender, gordon, shameful, intellect, gebcadredslpittedu, njxp\n",
      "Тема  5: drive, card, one, would, know, use, system, get\n",
      "Тема  6: game, year, team, one, think, like, good, would\n",
      "Тема  7: winner, division, captain, pittsburgh, april, pick, ranger, chicago\n",
      "Тема  8: philadelphia, san, game, era, pittsburg, save, germany, add\n",
      "Тема  9: window, file, use, program, problem, using, get, work\n",
      "Тема 10: thanks, please, would, anyone, email, know, information, like\n",
      "Тема 11: sale, shipping, offer, manual, asking, includes, used, new\n",
      "Тема 12: car, offer, price, new, sale, best, sell, condition\n",
      "Тема 13: would, people, one, dont, right, like, get, state\n",
      "Тема 14: would, one, car, get, like, thing, time, dont\n",
      "Тема 15: key, chip, would, government, phone, system, encryption, use\n",
      "Тема 16: tom, button, gehrels, aluminum, columbia, keywords, gamma, account\n",
      "Тема 17: water, plant, nuclear, president, air, tower, cooling, house\n",
      "Тема 18: object, cover, hard, physic, energy, company, pattern, unless\n",
      "Тема 19: one, god, people, dont, would, think, say, christian\n",
      "\n",
      "Вычисление финальной когерентности\n",
      "Тема  0:  2.591 - msg, food, chinese, turkey, reaction\n",
      "Тема  1:  3.671 - internet, everywhere, phone, corp, uucp\n",
      "Тема  2:  2.315 - cub, suck, bob, sea, stay\n",
      "Тема  3:  2.716 - thrush, contact, prevent, tube, spray\n",
      "Тема  4:  4.375 - bank, soon, surrender, gordon, shameful\n",
      "Время обучения: 758.91 секунд\n",
      "Когерентность: 1.5626\n",
      "Стандартное отклонение: 1.2330\n",
      "\n",
      "Улучшение качества:\n",
      "GridSearch: 1.2939\n",
      "Финальная: 1.5626\n",
      "Прирост: +0.2687\n",
      "\n",
      "Когерентность по темам:\n",
      "Тема  0:  2.591\n",
      "Тема  1:  3.671\n",
      "Тема  2:  2.315\n",
      "Тема  3:  2.716\n",
      "Тема  4:  4.375\n",
      "Тема  5:  0.371\n",
      "Тема  6:  0.323\n",
      "Тема  7:  2.418\n",
      "Тема  8:  0.555\n",
      "Тема  9:  0.587\n",
      "Тема 10:  0.450\n",
      "Тема 11:  1.324\n",
      "Тема 12:  0.878\n",
      "Тема 13:  0.323\n",
      "Тема 14:  0.246\n",
      "Тема 15:  0.939\n",
      "Тема 16:  2.135\n",
      "Тема 17:  3.122\n",
      "Тема 18:  1.469\n",
      "Тема 19:  0.445\n"
     ]
    }
   ],
   "source": [
    "def grid_search_with_sklearn():\n",
    "    \"\"\"Поиск параметров через sklearn GridSearchCV\"\"\"\n",
    "\n",
    "    param_grid = {\n",
    "        'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "        'beta': [0.01, 0.1, 0.5, 1.0]\n",
    "    }\n",
    "    \n",
    "    print(f\"Параметры для поиска:\")\n",
    "    print(f\"Alpha: {param_grid['alpha']}\")\n",
    "    print(f\"Beta: {param_grid['beta']}\")\n",
    "    print(f\"Всего комбинаций: {len(param_grid['alpha']) * len(param_grid['beta'])}\")\n",
    "    print()\n",
    "    \n",
    "    # Создаем GridSearchCV\n",
    "    lda_wrapper = LDAWrapper(n_iterations=50, random_state=42)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lda_wrapper,\n",
    "        param_grid=param_grid,\n",
    "        cv=2,\n",
    "        scoring=None,\n",
    "        n_jobs=1,\n",
    "        verbose=2,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    print(\"Начинаем GridSearch...\")\n",
    "    start_total = time.time()\n",
    "    \n",
    "    # Запускаем поиск\n",
    "    grid_search.fit(corpus)\n",
    "    \n",
    "    total_time = time.time() - start_total\n",
    "    print(f\"\\nGridSearch завершен за {total_time:.2f} секунд\")\n",
    "    \n",
    "    return grid_search\n",
    "\n",
    "\n",
    "print(\"Начинаем поиск лучших параметров\")\n",
    "grid_search = grid_search_with_sklearn()\n",
    "\n",
    "# Получаем результаты\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Результаты GridSearch\")\n",
    "\n",
    "print(f\"Лучшие параметры: alpha={best_params['alpha']}, beta={best_params['beta']}\")\n",
    "print(f\"Лучшая когерентность: {best_score:.4f}\")\n",
    "\n",
    "# Показываем все результаты\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "sorted_results = results_df.sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "print(\"\\nВсе результаты (отсортированы по когерентности):\")\n",
    "for i, (idx, row) in enumerate(sorted_results.iterrows(), 1):\n",
    "    alpha = row['param_alpha']\n",
    "    beta = row['param_beta']\n",
    "    score = row['mean_test_score']\n",
    "    print(f\"{i}. alpha={alpha:<3}, beta={beta:<3}: когерентность={score:.4f}\")\n",
    "\n",
    "BEST_ALPHA = best_params['alpha']\n",
    "BEST_BETA = best_params['beta']\n",
    "\n",
    "print(\"Финальное обучение с лучшими параметрами\")\n",
    "print(f\"Обучаем с лучшими параметрами: alpha={BEST_ALPHA}, beta={BEST_BETA}\")\n",
    "print(\"Увеличиваем итерации до 100 для максимального качества\")\n",
    "\n",
    "final_lda = CustomLDA(\n",
    "    n_topics=20, \n",
    "    alpha=BEST_ALPHA, \n",
    "    beta=BEST_BETA, \n",
    "    n_iterations=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "final_lda.fit(corpus, id_to_word)\n",
    "custom_time_end = time.time() - start_time\n",
    "\n",
    "print(f\"Финальное обучение завершено за {custom_time_end:.2f} секунд\")\n",
    "\n",
    "# Показываем финальные темы\n",
    "final_lda.print_topics()\n",
    "\n",
    "# Вычисляем финальную когерентность\n",
    "print(\"\\nВычисление финальной когерентности\")\n",
    "custom_coherence, custom_topic_coherences = calculate_topic_coherence(final_lda, corpus_texts)\n",
    "\n",
    "print(f\"Время обучения: {custom_time_end:.2f} секунд\")\n",
    "print(f\"Когерентность: {custom_coherence:.4f}\")\n",
    "print(f\"Стандартное отклонение: {np.std(custom_topic_coherences):.4f}\")\n",
    "\n",
    "print(f\"\\nУлучшение качества:\")\n",
    "print(f\"GridSearch: {best_score:.4f}\")\n",
    "print(f\"Финальная: {custom_coherence:.4f}\")\n",
    "print(f\"Прирост: {custom_coherence - best_score:+.4f}\")\n",
    "\n",
    "print(\"\\nКогерентность по темам:\")\n",
    "for i, coherence in enumerate(custom_topic_coherences):\n",
    "    print(f\"Тема {i:2d}: {coherence:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Сравнить результаты с эталонной реализацией из библиотеки [scikit-learn](https://scikit-learn.org/stable/):\n",
    "   * когерентность тем;\n",
    "   * время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение sklearn LDA с alpha=0.1, beta=1.0\n",
      "Sklearn обучение завершено за 43.00 секунд\n",
      "\n",
      "Sklearn темы:\n",
      "Тема  0: car, game, year, one, would, like, team, get\n",
      "Тема  1: god, christian, jesus, bible, church, christ, belief, christianity\n",
      "Тема  2: mywindow, surface, continental, neuron, developable, speaking, coolant, curve\n",
      "Тема  3: philadelphia, pittsburg, hartford, transaction, explosion, killed, idf, arens\n",
      "Тема  4: key, chip, encryption, clipper, phone, nsa, system, government\n",
      "Тема  5: bank, gordon, surrender, soon, intellect, shameful, chastity, njxp\n",
      "Тема  6: cell, gmt, patent, apr, bone, biker, university, nick\n",
      "Тема  7: bob, manhattan, blew, bronx, beauchaine, sank, bobbeviceicotekcom, queen\n",
      "Тема  8: detector, radar, receiver, oscillator, frequency, pat, nasa, lewis\n",
      "Тема  9: would, one, dont, people, think, know, like, get\n",
      "Тема 10: cview, april, caste, institute, rise, zone, edt, korea\n",
      "Тема 11: baerga, alomar, train, letter, tyre, chi, female, bos\n",
      "Тема 12: sale, offer, email, price, please, new, condition, interested\n",
      "Тема 13: cub, captain, suck, traded, element, zionism, shuttle, daily\n",
      "Тема 14: water, plant, heat, nuclear, cooling, tower, reactor, steam\n",
      "Тема 15: ground, wire, neutral, outlet, connected, breaker, box, antenna\n",
      "Тема 16: server, event, com, irq, client, openwindows, sun, expose\n",
      "Тема 17: space, moon, orbit, launch, nasa, earth, shuttle, satellite\n",
      "Тема 18: would, know, window, thanks, one, use, get, anyone\n",
      "Тема 19: pain, devguide, stone, mom, chop, laser, atm, stove\n",
      "\n",
      "Вычисление когерентности sklearn модели...\n",
      "Тема  0:  0.249 - car, game, year, one, would\n",
      "Тема  1:  1.879 - god, christian, jesus, bible, church\n",
      "Тема  2:  4.115 - mywindow, surface, continental, neuron, developable\n",
      "Тема  3:  2.691 - philadelphia, pittsburg, hartford, transaction, explosion\n",
      "Тема  4:  1.378 - key, chip, encryption, clipper, phone\n",
      "\n",
      "Sklearn - Когерентность по темам:\n",
      "Тема  0:  0.249\n",
      "Тема  1:  1.879\n",
      "Тема  2:  4.115\n",
      "Тема  3:  2.691\n",
      "Тема  4:  1.378\n",
      "Тема  5:  4.375\n",
      "Тема  6:  2.166\n",
      "Тема  7:  4.653\n",
      "Тема  8:  2.726\n",
      "Тема  9:  0.267\n",
      "Тема 10:  1.536\n",
      "Тема 11:  0.672\n",
      "Тема 12:  1.197\n",
      "Тема 13:  3.383\n",
      "Тема 14:  4.179\n",
      "Тема 15:  2.609\n",
      "Тема 16:  1.378\n",
      "Тема 17:  2.471\n",
      "Тема 18:  0.305\n",
      "Тема 19:  2.379\n",
      "\n",
      "Sklearn - Средняя когерентность: 2.2305\n",
      "Время обучения (сек)           758.91          43.00           715.91         \n",
      "Когерентность                  1.5626          2.2305          0.6679         \n",
      "Скорость: sklearn в 17.6x быстрее\n",
      "Разница когерентности: 0.6679\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для sklearn\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=len(word_to_id),\n",
    "    token_pattern=r'\\b\\w+\\b',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "X_sklearn = vectorizer.fit_transform(corpus_texts)\n",
    "sklearn_vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Создаем sklearn модель с оптимальными параметрами\n",
    "sklearn_lda = LatentDirichletAllocation(\n",
    "    n_components=20,\n",
    "    doc_topic_prior=BEST_ALPHA,\n",
    "    topic_word_prior=BEST_BETA,\n",
    "    max_iter=100,\n",
    "    learning_method='batch',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Обучение sklearn модели\n",
    "print(f\"\\nОбучение sklearn LDA с alpha={BEST_ALPHA}, beta={BEST_BETA}\")\n",
    "start_time = time.time()\n",
    "sklearn_lda.fit(X_sklearn)\n",
    "sklearn_training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Sklearn обучение завершено за {sklearn_training_time:.2f} секунд\")\n",
    "\n",
    "class SklearnLDAWrapper:\n",
    "    \"\"\"Wrapper для sklearn LDA, чтобы использовать ту же функцию когерентности\"\"\"\n",
    "    \n",
    "    def __init__(self, sklearn_model, vocabulary):\n",
    "        self.sklearn_model = sklearn_model\n",
    "        self.vocabulary = vocabulary\n",
    "        self.n_topics = sklearn_model.n_components\n",
    "        \n",
    "    def get_top_words(self, topic_id, n_words=10):\n",
    "        \"\"\"Имитирует метод самописной LDA модели\"\"\"\n",
    "        topic = self.sklearn_model.components_[topic_id]\n",
    "        top_words_ids = np.argsort(topic)[::-1][:n_words]\n",
    "        top_words = [(self.vocabulary[word_id], topic[word_id]) \n",
    "                     for word_id in top_words_ids]\n",
    "        return top_words\n",
    "\n",
    "# Создаем wrapper\n",
    "sklearn_wrapper = SklearnLDAWrapper(sklearn_lda, sklearn_vocabulary)\n",
    "\n",
    "# Показываем темы sklearn\n",
    "def print_sklearn_topics(model, feature_names, n_words=8):\n",
    "    print(\"\\nSklearn темы:\")\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[::-1][:n_words]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        words_str = ', '.join(top_words)\n",
    "        print(f\"Тема {topic_idx:2d}: {words_str}\")\n",
    "\n",
    "print_sklearn_topics(sklearn_lda, sklearn_vocabulary)\n",
    "\n",
    "print(\"\\nВычисление когерентности sklearn модели...\")\n",
    "\n",
    "sklearn_coherence, sklearn_topic_coherences = calculate_topic_coherence(\n",
    "    sklearn_wrapper, corpus_texts\n",
    ")\n",
    "\n",
    "print(\"\\nSklearn - Когерентность по темам:\")\n",
    "for i, coherence in enumerate(sklearn_topic_coherences):\n",
    "    print(f\"Тема {i:2d}: {coherence:6.3f}\")\n",
    "\n",
    "print(f\"\\nSklearn - Средняя когерентность: {sklearn_coherence:.4f}\")\n",
    "print(f\"{'Время обучения (сек)':<30} {custom_time_end:<15.2f} {sklearn_training_time:<15.2f} {abs(custom_time_end - sklearn_training_time):<15.2f}\")\n",
    "print(f\"{'Когерентность':<30} {custom_coherence:<15.4f} {sklearn_coherence:<15.4f} {abs(custom_coherence - sklearn_coherence):<15.4f}\")\n",
    "\n",
    "# Анализ результатов\n",
    "speed_ratio = custom_time_end / sklearn_training_time\n",
    "print(f\"Скорость: sklearn в {speed_ratio:.1f}x быстрее\")\n",
    "\n",
    "quality_diff = sklearn_coherence - custom_coherence\n",
    "\n",
    "print(f\"Разница когерентности: {quality_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Подготовить отчет, включающий:\n",
    "   * описание алгоритма латентного размещения Дирихле;\n",
    "   * описание датасета;\n",
    "   * результаты экспериментов;\n",
    "   * сравнение с эталонной реализацией;\n",
    "   * выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчет приложен в README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
