{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66def98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "from surprise import Dataset, Reader, SVD as SurpriseSVD\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36b1e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 943, Items: 1682, Ratings: 100000\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.data', \n",
    "    sep='\\t', \n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ")\n",
    "\n",
    "ratings.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "n_users = ratings.user_id.nunique()\n",
    "n_items = ratings.item_id.nunique()\n",
    "print(f\"Users: {n_users}, Items: {n_items}, Ratings: {len(ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc605018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModel:\n",
    "    def __init__(self, n_factors=50, learning_rate=0.005, reg=0.02, n_epochs=50):\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = learning_rate\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "    def fit(self, train):\n",
    "        self.global_mean = train.rating.mean()\n",
    "        self.user_biases = np.zeros(n_users)\n",
    "        self.item_biases = np.zeros(n_items)\n",
    "        self.user_factors = np.random.normal(scale=1/self.n_factors, size=(n_users, self.n_factors))\n",
    "        self.item_factors = np.random.normal(scale=1/self.n_factors, size=(n_items, self.n_factors))\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            for user, item, rating in train[['user_id', 'item_id', 'rating']].values:\n",
    "                user, item = int(user)-1, int(item)-1\n",
    "                \n",
    "                prediction = (\n",
    "                    self.global_mean \n",
    "                    + self.user_biases[user] \n",
    "                    + self.item_biases[item] \n",
    "                    + np.dot(self.user_factors[user], self.item_factors[item])\n",
    "                )\n",
    "                \n",
    "                error = rating - prediction\n",
    "                \n",
    "                self.user_biases[user] += self.lr * (error - self.reg * self.user_biases[user])\n",
    "                self.item_biases[item] += self.lr * (error - self.reg * self.item_biases[item])\n",
    "                \n",
    "                uf = self.user_factors[user]\n",
    "                itf = self.item_factors[item]\n",
    "                \n",
    "                self.user_factors[user] += self.lr * (error * itf - self.reg * uf)\n",
    "                self.item_factors[item] += self.lr * (error * uf - self.reg * itf)\n",
    "    \n",
    "    def predict(self, test):\n",
    "        preds = []\n",
    "        for user, item in test[['user_id', 'item_id']].values:\n",
    "            user, item = int(user)-1, int(item)-1\n",
    "            pred = (\n",
    "                self.global_mean \n",
    "                + self.user_biases[user] \n",
    "                + self.item_biases[item] \n",
    "                + np.dot(self.user_factors[user], self.item_factors[item])\n",
    "            )\n",
    "            preds.append(pred)\n",
    "        return np.clip(preds, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a7c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Model: RMSE = 0.9178, MAE = 0.7175, Time = 96.65s\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LatentFactorModel(n_factors=50, learning_rate=0.005, reg=0.02, n_epochs=50)\n",
    "start_time = time.time()\n",
    "model.fit(train)\n",
    "custom_train_time = time.time() - start_time\n",
    "\n",
    "preds = model.predict(test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test.rating, preds))\n",
    "mae = mean_absolute_error(test.rating, preds)\n",
    "print(f\"Custom Model: RMSE = {rmse:.4f}, MAE = {mae:.4f}, Time = {custom_train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f25e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise Model: RMSE = 0.9706, MAE = 0.7613, Time = 2.08s\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'item_id', 'rating']], reader)\n",
    "trainset, testset = surprise_train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "model = SurpriseSVD(n_factors=50, n_epochs=50, lr_all=0.005, reg_all=0.02)\n",
    "start_time = time.time()\n",
    "model.fit(trainset)\n",
    "surprise_train_time = time.time() - start_time\n",
    "\n",
    "surprise_preds = [model.predict(uid, iid).est for (uid, iid, _) in testset]\n",
    "\n",
    "y_true = [r for (_, _, r) in testset]\n",
    "rmse = np.sqrt(mean_squared_error(y_true, surprise_preds))\n",
    "mae = mean_absolute_error(y_true, surprise_preds)\n",
    "print(f\"Surprise Model: RMSE = {rmse:.4f}, MAE = {mae:.4f}, Time = {surprise_train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4e74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = ratings['user_id'].max() + 1\n",
    "pixar = [1, 71, 993] \n",
    "new_ratings = pd.DataFrame({\n",
    "    'user_id': [new_user_id] * 3,\n",
    "    'item_id': pixar,\n",
    "    'rating': [5, 5, 5]\n",
    "})\n",
    "updated_ratings = pd.concat([ratings, new_ratings], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e401faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentFactorModel(n_factors=50, learning_rate=0.005, reg=0.02, n_epochs=50)\n",
    "\n",
    "n_users = updated_ratings.user_id.nunique()\n",
    "n_items = updated_ratings.item_id.nunique()\n",
    "model.fit(updated_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecca8340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Casablanca (1942) [483]\n",
      "2. Schindler's List (1993) [318]\n",
      "3. Wrong Trousers, The (1993) [169]\n",
      "4. Wallace & Gromit: The Best of Aardman Animation (1996) [114]\n",
      "5. Usual Suspects, The (1995) [12]\n",
      "6. Shawshank Redemption, The (1994) [64]\n",
      "7. Rear Window (1954) [603]\n",
      "8. Pather Panchali (1955) [1449]\n",
      "9. 12 Angry Men (1957) [178]\n",
      "10. Star Wars (1977) [50]\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.item', \n",
    "    sep='|', \n",
    "    encoding='latin-1',\n",
    "    header=None,\n",
    "    names=['item_id', 'title'] + [f'f{i}' for i in range(23)]\n",
    ")[['item_id', 'title']]\n",
    "\n",
    "all_movies = ratings['item_id'].unique()\n",
    "\n",
    "input_data = pd.DataFrame({\n",
    "    'user_id': [new_user_id] * len(all_movies),\n",
    "    'item_id': all_movies\n",
    "})\n",
    "\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "results = input_data.copy()\n",
    "results['predicted_rating'] = predictions\n",
    "\n",
    "results = results.merge(movies, on='item_id', how='left')\n",
    "\n",
    "top_10 = results.sort_values('predicted_rating', ascending=False).head(10)\n",
    "for i, row in enumerate(top_10.itertuples(), 1):\n",
    "    print(f\"{i}. {row.title} [{row.item_id}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
