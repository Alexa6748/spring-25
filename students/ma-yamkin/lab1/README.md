# Описание метода

Данная работа содержит в себе ансамблевый метод машинного обучения RandomForestClassifier (бэггинг), написанный с использованием модуля DecisionTreeClassifier библиотеки sklearn. Агрегирование ответов от каждого дерева описывалось при помощи библиотеки numpy. Написанный метод сравнен по точности с реализацией RandomForestClassifier, реализвоанным с помощью sklearn и с одтельным деревом для понимания точности в сравнении с неансамблевым методом.

Бээинг работает следующим образом: каждый классификатор обучается на разных подвыборках из выборки с различными признаками, выборка осуществляется с возвращением. Каждый классификатор с использованием кросс-валидации проходит проверку на корректность (метрика accuracy должна превышать 0.6): тестирование проводится после обучения каждого классификатора с использованием тех данных, на которых классификатор обучался. Далее создается более сильный классификатор путем  агрегирвоания предсказаний классификаторов - мажоритарное агрегирование прогнозов на основе классификаторов, то есть конечным прогнозом будет класс с наибольшим количеством голосов.

Случайный лес — это частный, оптимизированный случай бэггинга и вставки на основе решающих деревьев.

# Описание датасета

Для обучения моделей будет использован Glass Classification датасет, где необходимо верно определить тип стекла по его признакам. Целевой признак (тип стекла) кодируются с помощью кодировщика LabelEncoder. Признаки включают в себя химические элементы и RI: refractive index.

# Результаты

В результате был обучен ансамбль RandomForestClassifier (гиперпараметры n_esimators=100 (количество классификаторов), max_samples=0.8 (размер выборки от исходной, на которой будет производиться обучение каждого классификатора)).

Значения метрик:

1. Accuracy: 0.69;
2. Recall: 0.74;
3. Precession: 0.71;
4. F1: 0.71;
5. Время: 0.11 с.

# Сравнение с эталоном:

Значения метрик sklearn RandomForestClassifier:

1. Accuracy: 0.69;
2. Recall: 0.76;
3. Precession: 0.69;
4. F1: 0.69;
5. Время: 0.09 с.

Значения метрик sklearn DecisionTreeClassifier:

1. Accuracy: 0.63;
2. Recall: 0.64;
3. Precession: 0.58;
4. F1: 0.59;
5. Время: 0.004 с.

# Выводы:

В задаче обосновано применение ансамблевых методов, поскольку они показывают большую точность. Значения метрик ансамблевого метода, написанного вручную и библиотечного обладают примерно одинаковыми значениями метрик, однако, библиотечная реализация работает быстрее.
