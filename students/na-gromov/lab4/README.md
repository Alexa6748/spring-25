# Лабораторная работа №4. Латентное размещение Дирихле (LDA)

## Описание

В данной лабораторной работе реализован алгоритм латентного размещения Дирихле (LDA) методом вариационного EM и проведено сравнение с эталонной реализацией из библиотеки `scikit-learn`. Для оценки качества тематических моделей использовались метрики когерентности тем (UMass и C_V), а также время обучения.

## Датасет

Для экспериментов использован стандартный текстовый датасет 20 Newsgroups.

## Ход работы

1. **Загрузка и предобработка данных**

   - Тексты приведены к нижнему регистру, токенизированы.
   - Построены словарь и корпус в формате bag-of-words (gensim).
   - Для LDA использована матрица частот слов (CountVectorizer, max_features=2000, фильтрация по частоте).

2. **Реализация LDA**

   - Собственная реализация LDA методом вариационного EM (`LDA_EM`).
   - Обучение на 10 темах, 50 итераций, гиперпараметры α=0.1, β=0.01.

3. **Сравнение с эталонной реализацией**

   - Использована модель `LatentDirichletAllocation` из `scikit-learn` с аналогичными параметрами.

4. **Оценка качества**
   - Для обеих моделей извлечены топ-10 слов для каждой темы.
   - Когерентность тем рассчитана с помощью метрик UMass и C_V (gensim).
   - Замерено время обучения моделей.

## Результаты

| Модель          | Время обучения | Когерентность UMass | Когерентность C_V |
| --------------- | -------------- | ------------------- | ----------------- |
| Собственная LDA | 174.17 сек     | -4.2270             | 0.5170            |
| sklearn LDA     | 2.23 сек       | -4.3693             | 0.4994            |

## Вывод

Собственная реализация LDA показывает довольно хорошее качество, как и реализация из `scikit-learn`, но работает сильно медленнее.
