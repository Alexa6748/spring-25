# Ансамбли моделей. Bagging

В данной лабораторной работе реализован метод бэггинга для задач классификации и регрессии. 
На основе sklearn деревьев реализованы кастомные методы бэггинга. Добавлено исключение из ансамбля, если модель предсказывает хуже, чем сулчайно. Применяется распараллеливание деревьев при обучении. Произведено сравнение с библиотечным решением. 

### Классификация
Выбранный датасет для классификации - пассажиры Титаника.
Для задачи классификации использовано 100 деревьев решений с максимальной глубиной 7. Оценка качества проводилась по accuracy.

### Регрессия
Выбранный датасет для регрессии - цены на жилье.
Для задачи регрессии использовано 100 деревьев решений с максимальной глубиной 7. Оценка качества проводилась по MSE.

## Результаты

| Метод             | Accuracy / MSE | Cross-Validation Accuracy / MSE | Training Time (seconds) |
| ----------------- | -------------- | ------------------------------- | ----------------------- |
| **Классификация** |                |                                 |                         |
| Custom Bagging    | 0.8240         | 0.8211                          | 0.5421                  |
| Sklearn Bagging   | 0.8240         | 0.8279                          | 0.2346                  |
| **Регрессия**     |                |                                 |                         |
| Custom Bagging    | 12.1613        | 11.8953                         | 0.5464                  |
| Sklearn Bagging   | 11.3649        | 21.6892                         | 0.3167                  |

## Вывод

- В задаче классификации Sklearn Bagging немного уступил в точности, но выигрывает по времени.
- В задаче регрессии Custom Bagging показал лучший результат на кросс-валидации, но хуже на тестовой выборке.
- Sklearn Bagging обучается быстрее, чем Custom Bagging, в обоих случаях на 100 моделях, но при меньшем количестве моделей время обучения у них схоже.
- Распараллеливание обучения простых моделей чаще приводит к увеличению общего времени из-за синхронизации потоков.
