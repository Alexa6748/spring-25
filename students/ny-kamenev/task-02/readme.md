# Градиентный бустинг

В данной лабораторной работе реализован метод градиентного бустинга для задач классификации и регрессии.
На основе sklearn деревьев реализованы кастомные методы градиентного бустинга. Произведено сравнение с библиотечным решением.

## Классификация
Выбранный датасет для классификации — пассажиры Титаника.
Для задачи классификации использовано 100 деревьев решений с максимальной глубиной 5. Оценка качества проводилась по accuracy.

### Результаты классификации

| Метод                     | Accuracy | Cross-Validation Accuracy | Training Time (seconds) |
|---------------------------|----------|---------------------------|-------------------------|
| **Custom Gradient Boosting** | 0.8165   | 0.8020                    | 0.2389                  |
| **Sklearn Gradient Boosting** | 0.8352   | 0.8212                    | 0.1907                  |

## Регрессия
Выбранный датасет для регрессии — цены на жилье.
Для задачи регрессии использовано 100 деревьев решений с максимальной глубиной 7. Оценка качества проводилась по MSE.

### Результаты регрессии

| Метод                     | MSE      | Cross-Validation MSE      | Training Time (seconds) |
|---------------------------|----------|---------------------------|-------------------------|
| **Custom Gradient Boosting** | 0.8240   | 0.8166                    | 0.2468                  |
| **Sklearn Gradient Boosting** | 0.8352   | 0.8212                    | 0.1976                  |

## Вывод

- В задаче классификации **Sklearn Gradient Boosting** показал более высокую точность, чем **Custom Gradient Boosting**, как на тестовой выборке, так и на кросс-валидации.
- В задаче регрессии **Sklearn Gradient Boosting** также продемонстрировал более высокую точность на тестовой выборке, но на кросс-валидации результаты оказались ближе.
- Время обучения **Sklearn Gradient Boosting** оказалось меньше, чем у **Custom Gradient Boosting**, что делает его более предпочтительным с точки зрения производительности.
- Разница в качестве между кастомной и библиотечной реализациями объясняется возможностями оптимизации в **Sklearn**, такими как улучшенное управление скоростью обучения и более эффективная работа с деревьями решений.

