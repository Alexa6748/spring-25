{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "from naive_bayes import NaiveBayes\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f924d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'sci.space',\n",
    "    'comp.graphics',\n",
    "    'soc.religion.christian'\n",
    "]\n",
    "\n",
    "X, y = fetch_20newsgroups(\n",
    "    categories=categories,\n",
    "    remove=('headers', 'footers', 'quotes') ,\n",
    "    return_X_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fbe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: 1776\n",
      "\n",
      "üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:\n",
      "- sci.space: 584 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
      "- comp.graphics: 593 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
      "- soc.religion.christian: 599 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
      "\n",
      "üìè –î–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤ —Å–ª–æ–≤–∞—Ö) –ø–æ –∫–ª–∞—Å—Å–∞–º:\n",
      "- sci.space:\n",
      "  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ : 157.8\n",
      "  ‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω–∞—è     : 62.0\n",
      "  ‚Ä¢ –ú–∏–Ω           : 0\n",
      "  ‚Ä¢ –ú–∞–∫—Å          : 9109\n",
      "  ‚Ä¢ üîΩ –°–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç: ¬´...¬ª\n",
      "  ‚Ä¢ üîº –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç : ¬´Archive-name: jpeg-faq\n",
      "Last-modified: 18 April 1993\n",
      "\n",
      "This FAQ article discusses JPEG image compressi...¬ª\n",
      "\n",
      "- comp.graphics:\n",
      "  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ : 202.3\n",
      "  ‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω–∞—è     : 82.0\n",
      "  ‚Ä¢ –ú–∏–Ω           : 0\n",
      "  ‚Ä¢ –ú–∞–∫—Å          : 6109\n",
      "  ‚Ä¢ üîΩ –°–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç: ¬´...¬ª\n",
      "  ‚Ä¢ üîº –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç : ¬´COMMERCIAL SPACE NEWS/SPACE TECHNOLOGY INVESTOR NUMBER 22\n",
      "\n",
      "   This is number twenty-two in an irregu...¬ª\n",
      "\n",
      "- soc.religion.christian:\n",
      "  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ : 262.8\n",
      "  ‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω–∞—è     : 157.0\n",
      "  ‚Ä¢ –ú–∏–Ω           : 0\n",
      "  ‚Ä¢ –ú–∞–∫—Å          : 2939\n",
      "  ‚Ä¢ üîΩ –°–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç: ¬´...¬ª\n",
      "  ‚Ä¢ üîº –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç : ¬´I have come across what I consider to be an excellent tract. It is a\n",
      "bit lengthy for a posting, but ...¬ª\n",
      "\n",
      "üî° –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (–ø–æ—Å–ª–µ CountVectorizer):\n",
      "- sci.space: 10592 —Å–ª–æ–≤\n",
      "- comp.graphics: 13273 —Å–ª–æ–≤\n",
      "- soc.religion.christian: 11521 —Å–ª–æ–≤\n",
      "\n",
      "üß† –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –≤–æ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö: 25381\n"
     ]
    }
   ],
   "source": [
    "target_names = categories\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X_vec = vectorizer.fit_transform(X) \n",
    "\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "vocab_set = set(vocab)\n",
    "\n",
    "docs_by_class = defaultdict(list)\n",
    "lengths_by_class = defaultdict(list)\n",
    "\n",
    "for doc, label in zip(X, y):\n",
    "    words = doc.split()\n",
    "    lengths_by_class[target_names[label]].append(len(words))\n",
    "    docs_by_class[target_names[label]].append(doc)\n",
    "\n",
    "\n",
    "word_sets_by_class = {}\n",
    "for class_name, docs in docs_by_class.items():\n",
    "    class_text = \" \".join(docs)\n",
    "    tokens = vectorizer.build_analyzer()(class_text) \n",
    "    word_sets_by_class[class_name] = set(tokens)\n",
    "\n",
    "print(f\"üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(X)}\\n\")\n",
    "\n",
    "print(\"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:\")\n",
    "for class_name in target_names:\n",
    "    print(f\"- {class_name}: {len(docs_by_class[class_name])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
    "print()\n",
    "\n",
    "print(\"üìè –î–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤ —Å–ª–æ–≤–∞—Ö) –ø–æ –∫–ª–∞—Å—Å–∞–º:\")\n",
    "for class_name in target_names:\n",
    "    lengths = lengths_by_class[class_name]\n",
    "    print(f\"- {class_name}:\")\n",
    "    print(f\"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ : {np.mean(lengths):.1f}\")\n",
    "    print(f\"  ‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω–∞—è     : {np.median(lengths):.1f}\")\n",
    "    print(f\"  ‚Ä¢ –ú–∏–Ω           : {np.min(lengths)}\")\n",
    "    print(f\"  ‚Ä¢ –ú–∞–∫—Å          : {np.max(lengths)}\")\n",
    "\n",
    "    min_idx = np.argmin(lengths)\n",
    "    max_idx = np.argmax(lengths)\n",
    "    print(f\"  ‚Ä¢ üîΩ –°–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç: ¬´{docs_by_class[class_name][min_idx][:100]}...¬ª\")\n",
    "    print(f\"  ‚Ä¢ üîº –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç : ¬´{docs_by_class[class_name][max_idx][:100]}...¬ª\\n\")\n",
    "\n",
    "print(\"üî° –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (–ø–æ—Å–ª–µ CountVectorizer):\")\n",
    "for class_name in target_names:\n",
    "    print(f\"- {class_name}: {len(word_sets_by_class[class_name])} —Å–ª–æ–≤\")\n",
    "\n",
    "print(f\"\\nüß† –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –≤–æ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö: {len(vocab_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ae853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    CountVectorizer(stop_words=\"english\"), \n",
    "    NaiveBayes(alpha=1.0)\n",
    ")\n",
    "\n",
    "sk_pipeline = make_pipeline(\n",
    "    CountVectorizer(stop_words=\"english\"), \n",
    "    MultinomialNB(alpha=1.0)\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2202d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_cv(model, X, y, cv=5, average='macro'):\n",
    "    scoring = {\n",
    "        'accuracy':  make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score, average=average, zero_division=0),\n",
    "        'recall':    make_scorer(recall_score, average=average, zero_division=0),\n",
    "        'f1':        make_scorer(f1_score, average=average, zero_division=0)\n",
    "    }\n",
    "\n",
    "    scores = cross_validate(model, X, y, scoring=scoring, cv=cv, return_train_score=False)\n",
    "\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    result_df = pd.DataFrame({m: scores[f'test_{m}'] for m in metrics})\n",
    "    result_df.loc['mean'] = result_df.mean()\n",
    "\n",
    "    print(f\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ ({cv.n_splits}-fold, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ: '{average}'):\\n\")\n",
    "    print(result_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06efda11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ (5-fold, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ: 'macro'):\n",
      "\n",
      "      accuracy  precision  recall      f1\n",
      "0       0.8933     0.9043  0.8930  0.8933\n",
      "1       0.8986     0.9017  0.8985  0.8982\n",
      "2       0.9183     0.9215  0.9181  0.9182\n",
      "3       0.9127     0.9164  0.9121  0.9121\n",
      "4       0.9099     0.9139  0.9094  0.9095\n",
      "mean    0.9065     0.9116  0.9062  0.9063\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_cv(pipeline, X, y, cv=cv, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55066622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ (5-fold, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ: 'macro'):\n",
      "\n",
      "      accuracy  precision  recall      f1\n",
      "0       0.8933     0.9043  0.8930  0.8933\n",
      "1       0.8986     0.9017  0.8985  0.8982\n",
      "2       0.9183     0.9215  0.9181  0.9182\n",
      "3       0.9127     0.9164  0.9121  0.9121\n",
      "4       0.9099     0.9139  0.9094  0.9095\n",
      "mean    0.9065     0.9116  0.9062  0.9063\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_cv(sk_pipeline, X, y, cv=cv, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43639fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696 ms ¬± 1.77 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cross_validate(pipeline, X, y, scoring='accuracy', cv=cv, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85857241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707 ms ¬± 5.66 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cross_validate(sk_pipeline, X, y, scoring='accuracy', cv=cv, return_train_score=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
