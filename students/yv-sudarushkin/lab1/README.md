# Лабораторная работа №1. Ансамбли моделей  
## Реализация бэггинга для классификации на датасете Electricity Market

---

### 1. Описание метода  
**Бэггинг (Bootstrap Aggregating)** — метод ансамблирования, основанный на:
- Параллельном обучении **независимых базовых моделей** на случайных подвыборках
- **Усреднении результатов** предсказаний (для классификации — голосовании)

**Особенности реализации:**
- Базовые модели: `DecisionTreeClassifier`
- Отбор моделей с пороговыми значениями accuracy

---

### 2. Описание датасета  
**[Kaggle Electricity Market Dataset](https://www.kaggle.com/datasets/vstacknocopyright/electricity)** (Новый Южный Уэльс, Австралия):  
- **Цель**: Предсказание направления изменения цены на электроэнергию (бинарная классификация: UP/DOWN)
- **Признаки** (8 числовых):
  - Спрос и предложение электроэнергии
  - Температура
  - Время суток
  - Перетоки между штатами
- **Объем**: 45,312 наблюдений
---

### 3. Результаты экспериментов  

#### 3.1 Метрики качества  

| Метрика       | Кастомная реализация | Sklearn (BaggingClassifier) |
|---------------|----------------------|-----------------------------|
| **Accuracy**  | 0.9055               | 0.9018                      |
| **Precision** | 0.9084 → 1 класс     | 0.9092 → 1 класс            |
|               | 0.9036 → 0 класс     | 0.8969 → 0 класс            |
| **Recall**    | 0.8629 → 1 класс     | 0.8521 → 1 класс            |
|               | 0.9366 → 0 класс     | 0.9380 → 0 класс            |
| **F1-score**  | 0.8851 → 1 класс     | 0.8798 → 1 класс            |
|               | 0.9198 → 0 класс     | 0.9170 → 0 класс            |

#### 3.2 Время обучения  
```python
Время, затраченное кастомным: 2.5664 с  
Время, затраченное Sklearn: 1.6978 с
```

#### 3.3 Кросс-валидация (10 запусков)  
```python
Средний accuracy для 10 выборок:
- Кастомная модель: 0.907
- Sklearn: 0.904
```

---

### 4. Сравнение с эталонной реализацией  

| Критерий       | Кастомная модель          | Sklearn                   |
|----------------|---------------------------|---------------------------|
| Точность       | **Незначительно выше**    | Немного ниже              |
| Скорость       | Медленнее на ~33%         | **Оптимизирована**        |

---

### 5. Выводы  

1. **Эффективность бэггинга** подтверждена: обе реализации показывают accuracy > 90%
2. **Кастомная реализация по сравнению с эталоном**:
   - Преимущество: Лучшее качество за счет отсева слабых моделей
   - Недостаток: Более долгое обучение из-за проверки пороговых значений
