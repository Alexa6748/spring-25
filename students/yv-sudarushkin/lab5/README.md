# Лабораторная работа №5. Модель латентных факторов (LFM)

## Цель

Реализовать модель латентных факторов (Latent Factor Model, LFM), обучить её на реальном датасете, сравнить по качеству и скорости с эталонной реализацией из библиотеки, а также оценить качество предсказаний с помощью метрик (RMSE/MAE).

---

## Используемый датасет

**Источник:** [Anime Recommendations Database](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database) (`rating.csv`)

**Формат данных:** тройки `user_id`, `anime_id`, `rating`

**Объём после фильтрации (по `user_id < 4000`, `anime_id < 4000`):**
- Пользователей: ~3.4 тыс.
- Аниме: ~2.5 тыс.
- Оценок: **89 416**

Фильтрация необходима для ограничения объёма данных и ускорения вычислений.

---

## Описание модели латентных факторов

Модель латентных факторов — это метод матричной факторизации, применяемый в рекомендательных системах. Он аппроксимирует исходную матрицу взаимодействия \( R \) (пользователь × объект) как произведение двух матриц меньшей размерности:

$$R \approx P \cdot Q^T$$

Где:
- $P (n_{users}; k)$ — матрица латентных признаков пользователей
- $Q (n_{items}; k)$ — матрица латентных признаков объектов (аниме)
- $k$ — число латентных признаков (гиперпараметр)

**Обучение:** с помощью стохастического градиентного спуска (SGD) с регуляризацией.

Формула обновления:
```python
err = rating - P[u] @ Q[i].T
P[u] += lr * (err * Q[i] - reg * P[u])
Q[i] += lr * (err * P[u] - reg * Q[i])
````

---

## Параметры обучения модели

| Параметр         | Значение |
| ---------------- | -------- |
| `n_factors`      | 30       |
| `learning_rate`  | 0.01     |
| `regularization` | 0.1      |
| `n_epochs`       | 50       |

---

## Результаты экспериментов

| Метрика / Время    | Собственная реализация | Surprise (эталон) |
| ------------------ | ---------------------- | ----------------- |
| RMSE               | 1.4769                 | 1.2344 ± 0.0114   |
| Время обучения     | \~62 сек               | \~0.545 сек       |
| Время предсказания | \~436 мс               | \~125 мс          |

Оценка Surprise выполнена с помощью `cross_validate()` на 5 фолдах с `SVD`.

---

## Выводы

* **Скорость**: эталонная реализация `surprise.SVD` значительно быстрее по времени обучения (в \~100 раз), благодаря оптимизированному backend и эффективному использованию NumPy.
* **Качество**: RMSE модели `surprise` немного ниже.
* **Своя реализация** позволяет гибко понять внутренности модели и использовать модификации: работу с разреженными матрицами, контролем за нормой градиентов и инициализацией.
